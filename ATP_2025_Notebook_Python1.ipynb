{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI7ILJF3M2cBpGGiajcvoY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/ATP_2025_Notebook_Python1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s2xlXLg29lw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic exercises Mon December 15th\n",
        "\n",
        "1) Make yourself a new directory for python scripts in the server. Copy all `.py` scripts from /home/jmnybl/python-lecture to your new directory.\n",
        "\n",
        "2) Open `analyze_file.py` with less/nano to see how it refers to the input. Run the script.\n",
        "\n",
        "3) Open `analyze.py` with less/nano to see how it refers to the input. Run the script. Use /home/jmnybl/python-lecture/data.conllu as input.\n",
        "\n",
        "4) Open `filter.py` with less/nano to see how it refers to the input/output. Run the script, it keeps only sentences with subject – “tarvita” – object structure. Use /home/jmnybl/python-lecture/data.conllu as input. Combine `filter.py` with relevant bash commands (e.g. `egrep`) to figure out what is the most common object lemma (“obj” relation) before and after filtering?\n",
        "\n",
        "--> Note that in (4) it's okay to count all objects of the filtered sentences, not just objects of the verb \"tarvita\". (If you would like to do that, simplest would be to do it in python since bash commands do not easily suppport that)."
      ],
      "metadata": {
        "id": "Nl9zXh7e3GCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra exercises\n",
        "\n",
        "5) Open `json_example.py`, and try to understand what it does. Run the script (it does not expect any input). This creates you a new file called data.json. Open the data.json with less/nano to see how it looks.\n",
        "\n",
        "6) If you are familiar with python, try to understand the filtering function in `filter.py`. What kind of filtering functions you could implement yourself?\n"
      ],
      "metadata": {
        "id": "bxjPKD_Z4l2D"
      }
    }
  ]
}