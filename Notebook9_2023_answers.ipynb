{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2YaAm2zJ0jGn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/Notenook9_2022_answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please use the server to do these exercises. If you are unfamiliar with scripts, you can also start with the time-out exercises listed on Notebook8**\n",
        "\n",
        "## Exercise 1\n",
        "\n",
        "The Github repo https://github.com/MarkHershey/CompleteTrumpTweetsArchive has all the tweets published by Donald Trump when he was at office. Clone the repo to your home folder on the server.\n",
        "\n",
        "### 1.1 \n",
        "Count the most frequent hashtags and / or handles of the dataset covering Tweets when Trump was in office. Make sure to ignore possible punctuations, such as \n",
        "```\n",
        "@realDonaldTrump:\n",
        "@realDonaldTrump\n",
        "```\n",
        "### 1.2 \n",
        "Make a script that takes as argument a handle and prints out its distribution over time month by month. Run the script on a couple of interesting handles / hashtags. Do you see any trends?\n",
        "\n",
        "**Extra:** sort the output so that you have the tweets ordered from older to newer, followed by the number of tweets for that time stamp, like\n",
        "\n",
        "```\n",
        "YEAR-MONTH1 NUM-OF-TWEETS\n",
        "YEAR-MONTH2 NUM-OF-TWEETS\n",
        "```\n",
        "If you get a permission denied error, you have forgotten to add execution rights to your script. This can be done with `chmod a+rwx file.txt`\n",
        "\n",
        "### 1.3 \n",
        "Make another script that takes as argument a handle and prints out a cleaned and normalized frequency list of the words that occur in the tweets with the handle. \n",
        "\n",
        "You can try out different ways of cleaning the data. Does it make sense to include tokens with numbers and / or punctuation at all? Or is it better to just, e.g., delete tokens and numbers and otherwise otherwise keep the strings there?\n",
        "\n",
        "### 1.4 Advanced\n",
        "\n",
        "The output of 1.3 would be much better if it excluded function words, don't you think?\n",
        "\n",
        "Trankit is super slow and cannot be run on the server. But UdPipe can - the performance is lower, but maybe it would be enough. Let's try!\n",
        "\n",
        "UdPipe documentation can be found at https://lindat.mff.cuni.cz/services/udpipe/api-reference.php \n",
        "\n",
        "With the following call, UdPipe prints to standard output the conllu analysis of the input file, here called delme.csv\n",
        "\n",
        "`curl -F data=@delme.csv -F model=english -F tokenizer= -F tagger= -F parser= http://lindat.mff.cuni.cz/services/udpipe/api/process | PYTHONIOENCODING=utf-8 python -c \"import sys,json; sys.stdout.write(json.load(sys.stdin)['result'])\" `\n",
        "\n",
        "If you have time, try to implement a script that is similar to 1.3 but outputs only content POS classes, such as nouns, verbs, etc, instead of all most frequent words, and lemmas instead of running words.\n",
        "\n",
        "You can try with different POS classes to figure out the most useful output in your opinion. What happens if you include only nouns? or proper nouns? or adjetives? or all these classes?\n",
        "\n",
        "### Tips\n",
        "A new perl script can be useful for modifying strings. This example would replace all instances of REPLACED with ORIGINAL.\n",
        "\n",
        "```\n",
        "cat inputfile.txt | perl -pe 's/ORIGINAL/REPLACED/g'\n",
        "```\n",
        "\n",
        "This script supports also back reference, so you can refer to expressions in `ORIGINAL` and refer to those with `$` in `REPLACED`. Like here any punctuation is replaced by a newline and that punctuation\n",
        "\n",
        "```\n",
        " perl -pe 's/([[:punct:]])/\\n$1/g' \n",
        "```\n",
        "----------------\n",
        "\n",
        "Note that in a script, you can have various commands, and all the commands will be executed one by one (with the exception of pipes, where the commands are executed all at once).\n",
        "\n",
        "For instance if a script has the two commands below, it will first print \"kukkuu\" to a file called delme.txt, and then, undepending of the first one, print the file and egrep lines correspomding to \"kuu\".\n",
        "\n",
        "```\n",
        "echo \"kukkuu\" > delme.txt\n",
        "\n",
        "cat delme.txt | egrep \"kuu\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "2YaAm2zJ0jGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some solutions\n",
        "\n",
        "Note: pls make these on the course server. The scripts are also readable and runnable at \n",
        "/home/mavela/course-2022/notebook9-scripts\n",
        "\n",
        "\n",
        "### 1.1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D7Xp59QHadqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/MarkHershey/CompleteTrumpTweetsArchive.git"
      ],
      "metadata": {
        "id": "ksNWGsN0afrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CompleteTrumpTweetsArchive/data/\n",
        "! ls"
      ],
      "metadata": {
        "id": "Tn2ANU6Dai5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to count the hashtags\n",
        "# note that perl -pe 's/[[:punct:]]$//g' will replace any punctuation followed by a line ending with nothing\n",
        "\n",
        "! cat realDonaldTrump_in_office.csv | cut -f 4 -d ',' | tr ' ' '\\n' | egrep \"#\" | perl -pe 's/[[:punct:]]$//g' | sort | uniq -c | sort -rn | head\n"
      ],
      "metadata": {
        "id": "ncGiRKpTajxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2"
      ],
      "metadata": {
        "id": "abM-UtASpyey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to the script to count the time distribution of the tweets including a specific handle / hashtag, given as an argument\n",
        "# so this could be run e.g. with cat tweets.csv | ./script.sh handle\n",
        "\n",
        "! cat realDonaldTrump_in_office.csv | egrep -i $1 | cut -f 2 -d ',' | cut -f 2 -d ' ' | cut -f 1,2 -d '-'| sort | uniq -c\n"
      ],
      "metadata": {
        "id": "OWxUAUzfa5vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXTRA:\n",
        "#sort -k2 sorts the output by the second column, and the perl script with some regexes can be used to change the columns\n",
        "\n",
        "! cat tweets.csv | ./script.sh handle | sort -k2 -n | perl -pe 's/^ *([0-9]+) ([0-9-]+)/$2 $1/g' "
      ],
      "metadata": {
        "id": "-z0dJ41akH4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the script runs in my folder /home/mavela/course-2022/notebook9-scripts on the server with\n",
        "cat ../CompleteTrumpTweetsArchive/data/realDonaldTrump_in_office.csv | ./handlrefreqs.sh @WhiteHouse  | less\n"
      ],
      "metadata": {
        "id": "Sl15CaUSsWJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 "
      ],
      "metadata": {
        "id": "rlWhhyxGqG3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to count the most frequent words associated with a handle\n",
        "# Note that this one ignores all rows - tokens - including a number or punctuation. I think this gave somewhat cleaner results.\n",
        "# at least for @IvankaTrump I get words like *thank, thanks* and *commited, workforce, working* which hint the contents of these tweets\n",
        "\n",
        "! cat realDonaldTrump_in_office.csv | egrep -i $1 | cut -f 4 -d ',' | tr ' ' '\\n' | egrep -v '[[:punct:]]|[0-9]'  | tr '[[:upper:]]' '[[:lower:]]'| sort | uniq -c | sort -rn\n"
      ],
      "metadata": {
        "id": "65OpQP_MqFk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the script runs in my folder /home/mavela/course-2022/notebook9-scripts on the server with\n",
        "\n",
        "cat ../CompleteTrumpTweetsArchive/data/realDonaldTrump_in_office.csv | ./words_in_handle.sh @WhiteHouse  | less"
      ],
      "metadata": {
        "id": "fOMELFuIuB7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4"
      ],
      "metadata": {
        "id": "RdcD2y3oIMIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the script runs in my folder /home/mavela/course-2022/notebook9-scripts on the server with\n",
        "\n",
        " cat ../CompleteTrumpTweetsArchive/data/realDonaldTrump_in_office.csv | ./conllu_in_handle.sh @WhiteHouse  | less\n"
      ],
      "metadata": {
        "id": "qLUCz97rINi8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
