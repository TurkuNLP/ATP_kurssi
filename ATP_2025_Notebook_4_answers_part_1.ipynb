{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/ATP_2025_Notebook_4_answers_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5iQFtKV0BMP"
      },
      "source": [
        "# Today's topics\n",
        "\n",
        "I Cloning Github repos\n",
        "\n",
        "II Gzipped files using `gzip` and `zcat`\n",
        "\n",
        "III Changing characters using `tr`\n",
        "  * Combining `tr` to a frequency list pipeline\n",
        "  * Using `tr` to normalize\n",
        "\n",
        "IV Regular expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICHHIGKhbr4l"
      },
      "source": [
        "### I Copying a Github repo\n",
        "\n",
        "Github is a common place to save code and data in NLP. The repos (directories) can be copied to a local computer programatically.\n",
        "\n",
        "This is quite handy especially with Google colab.\n",
        "\n",
        "The command for the copying is `git clone`, and it should be followed the url \"Code\" link in the **green box** available at a Git repo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBBc_B2z96Da"
      },
      "source": [
        "###Let's start by fetching some data from Github.\n",
        "\n",
        "1. Clone the following repo: https://github.com/TurkuNLP/CORE-corpus.git and check that we got it.\n",
        "\n",
        "2. In the repo, there's a folder called CORE-corpus. Go to the folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVWyz9Eh04FT"
      },
      "outputs": [],
      "source": [
        "#1. Clone the repo\n",
        "\n",
        "! git clone https://github.com/TurkuNLP/CORE-corpus.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmwLx7fyaXJr"
      },
      "outputs": [],
      "source": [
        "#Check that we got it\n",
        "\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4-bZa7906Pz"
      },
      "outputs": [],
      "source": [
        "#2. Go to the folder\n",
        "\n",
        "# cd will take us there\n",
        "\n",
        "%cd CORE-corpus/\n",
        "! ls # check that we are at the correct place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMbg83cCb_IW"
      },
      "source": [
        "### II Gzipped files: basic check-ups\n",
        "\n",
        "* `zcat` for printing\n",
        "* `gzip` for producing (writing in a zipped file)\n",
        "\n",
        "---\n",
        "* You need to print `gz` files before you can process **zipped** files\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vDDkEKu-ViH"
      },
      "source": [
        "###Next\n",
        "\n",
        "3. Print the train file within the folder, i.e., always `zcat file.tsv.gz`\n",
        "4. The first column in the file indicates the register label for the text. Check what the abbreviations mean. The CORE-corpus folder contains a file register_label_abbreviations.txt that features all the abbreviations for the register labels.\n",
        "5. Then count the lines (since the data is in the form text per line, you get the number of texts in the file by counting the lines in the file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0R7u_8FcpVp"
      },
      "outputs": [],
      "source": [
        "#3. Print the file\n",
        "! zcat train.tsv.gz | head # what's in the file?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqgMFLBqsqL3"
      },
      "outputs": [],
      "source": [
        "# Register labels are in the first column\n",
        "! zcat train.tsv.gz | cut -f 1 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyA9ygSHBXJR"
      },
      "outputs": [],
      "source": [
        "#4. Check what the labels are.\n",
        "\n",
        "! head register_label_abbreviations.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIyGj3VYcTSy"
      },
      "outputs": [],
      "source": [
        "#5. Line (in this case also text) count\n",
        "\n",
        "! zcat train.tsv.gz | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51dH0EYtUn4D"
      },
      "source": [
        "###Try the commands yourselves.\n",
        "\n",
        "1. Check what the `test` file includes.\n",
        "2. And do the line count for the `test` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KVMTyJ--Uc2"
      },
      "outputs": [],
      "source": [
        "# 1. Check what the *test* file includes\n",
        "! zcat test.tsv.gz | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzk8o-ijAzjA"
      },
      "outputs": [],
      "source": [
        "# 2. And do the line count for the *test* file\n",
        "! zcat test.tsv.gz | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qykucyudjLU"
      },
      "source": [
        "### Focus on specific columns\n",
        "\n",
        "A reminder:\n",
        "\n",
        "` cut -f `\n",
        "\n",
        "Columns in a file can be accessed with the ` cut -f ` command. The **column must be specified** in the command with the flag `-f`. E.g.,\n",
        "\n",
        "`cut -f 5`\n",
        "\n",
        "prints the 5th column in the file.\n",
        "\n",
        "**Note** the white spaces in the command! If they are incorrect, you'll get an error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gno-JVVZwEJF"
      },
      "source": [
        "##Exercise 1\n",
        "\n",
        "1. Print the text column in the `train` file and check that you got it right.\n",
        "2. Check what the different columns have.\n",
        "3. Check the columns in the file `register_label_abbreviations.txt`. What do you get with `cut -f 3`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjCSkWcCd1J2"
      },
      "outputs": [],
      "source": [
        "# 1. Print the text column (the 3rd column) in the train file and check that you got it right.\n",
        "\n",
        "#check with head\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcqDBqEnGlSg"
      },
      "outputs": [],
      "source": [
        "# 2. Check what the different columns have.\n",
        "! zcat train.tsv.gz | cut -f 1 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAbits7VG7j9"
      },
      "outputs": [],
      "source": [
        "# 3. Check the columns in the file register_label_abbreviations.txt. What do you get with cut -f 3?\n",
        "! cat register_label_abbreviations.txt | cut -f 1 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emqO8IV4HJfi"
      },
      "outputs": [],
      "source": [
        "#What happens if you try cut -f 3 on the file register_label_abbreviations.txt?\n",
        "! cat register_label_abbreviations.txt | cut -f 3 | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP1eCauOeSIY"
      },
      "source": [
        "##Exercise 2\n",
        "\n",
        "### Filtering away the duplicates and the empty lines\n",
        "\n",
        "Unfortunately, the train file has some duplicates and empty documents. Before we move on, make a file that includes only the text parts of the file, and no duplicates or empty documents. It's advisable to use e.g. line count and frequency list to check that everything that was supposed to be removed is removed.\n",
        "\n",
        "Make a clean version of the file in which you include **only the texts**.\n",
        "1. Remove **all empty lines** and\n",
        "2. **duplicates**.\n",
        "3. Direct the output in a **new file** called `cleaned.txt.gz`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ez6XC-ffxCV"
      },
      "outputs": [],
      "source": [
        "# 1. First, check how many lines there are in the original file.\n",
        "\n",
        "#N.B. Here, when you count the lines, you get the number of docs/texts\n",
        "\n",
        "! zcat train.tsv.gz | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | cut -f 3 | head"
      ],
      "metadata": {
        "id": "lKIBRmJUC8a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geiidh0TB8Cr"
      },
      "outputs": [],
      "source": [
        "#Then, check how many empty lines (in the text column) the file includes.\n",
        "\n",
        "#cut -f 3: access the text column\n",
        "#egrep \"^$\": get the empty lines (^ line start, $ line end)\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep \"^$\" | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-GRa90-FbfK"
      },
      "outputs": [],
      "source": [
        "#Check that all the empty lines are removed (count the remaining lines after the removal of the empty ones).\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a3RpXoz7XSB"
      },
      "outputs": [],
      "source": [
        "# 2. Check the duplicates in the file.\n",
        "\n",
        "#sort: sort the lines alphabetically\n",
        "#uniq -c: counts the number of consequtive duplicate lines\n",
        "#sort -rn: n sorts according to numbers, r sorts in reverse order (descending order)\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq -c | sort -rn | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-UvG9r6b86c"
      },
      "outputs": [],
      "source": [
        "#Count how many unique non-empty docs there are in the file.\n",
        "\n",
        "#sort: sorts alphabetically\n",
        "#uniq: prints only once each (duplicate) line\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | wc -l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lZxTJuM7Cl6"
      },
      "outputs": [],
      "source": [
        "# 3. Direct the output to a new file.\n",
        "\n",
        "#gzip: create a gzipped file\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | gzip > cleaned.txt.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYSBQ8YixrXL"
      },
      "outputs": [],
      "source": [
        "# Check that the new file exists.\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1SKwp1exwtq"
      },
      "outputs": [],
      "source": [
        "# Check the file contents.\n",
        "! zcat cleaned.txt.gz | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prPtXTuSVmBH"
      },
      "source": [
        "**EXTRA TIME LEFT?**\n",
        "\n",
        "Clean the test file as above (i.e. do all the same things for the test file as for the train file). Remember to check the output of each pipe so you can be sure that you end up with the intended final output. Finally, direct the output of the cleaned test file to a new file called `cleaned_test_file.txt.gz`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7d_6tzwKg5u"
      },
      "outputs": [],
      "source": [
        "#Clean the test file.\n",
        "\n",
        "! zcat test.tsv.gz | cut -f 3 | head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | wc -l"
      ],
      "metadata": {
        "id": "9dsodSMXO0pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | egrep \"^$\" | wc -l"
      ],
      "metadata": {
        "id": "XJ1umw2BOhAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | egrep -v \"^$\" | wc -l"
      ],
      "metadata": {
        "id": "QXJFAgUqOxuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | head"
      ],
      "metadata": {
        "id": "D_1xv5Z0OuFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | wc -l"
      ],
      "metadata": {
        "id": "nDEcewulO9-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iwz6mRtCLyZ"
      },
      "source": [
        "### III Changing characters\n",
        "\n",
        "Changing characters is often a useful thing to do:\n",
        "* **Splitting** tokens to one per line (a useful format for Bash), i.e. the format is **word per line**\n",
        "* Splitting **to sentences**\n",
        "* **Normalization** (i.e. all to lower case)\n",
        "* **Deleting** punctuation or numbers\n",
        "\n",
        "### Using `tr` to split tokens one per line\n",
        "* `tr` refers to transform\n",
        "* use **single quotation** marks to indicate **what is transformed** (within first single quotation marks) and **to what** (within the second single quotation marks)\n",
        "\n",
        "  e.g. `tr ' ' '\\n'`\n",
        "\n",
        "  transforms white space (' ') to a line break ('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r97IcEtrHUtS"
      },
      "source": [
        "##Let's try this.\n",
        "1. **Split the tokens** one per line in the file `cleaned.txt.gz`\n",
        "2. **Direct the output** (the word-per-line output) to `outputfile.txt`\n",
        "3. **Count the lines** in the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0mO0GE2CgzM"
      },
      "outputs": [],
      "source": [
        "#1. Word per line: the contents of the first ' ' is transformed to the contents of the second ' '\n",
        "#In the present context this means that each white space is transformed to line break\n",
        "\n",
        "# ' ' refers to white space\n",
        "# '\\n' refers to new line\n",
        "\n",
        "! zcat cleaned.txt.gz | tr ' ' '\\n' | head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0HVeK_5DBJN"
      },
      "outputs": [],
      "source": [
        "#Compare to the original file\n",
        "\n",
        "! zcat cleaned.txt.gz | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m6Zwm8Sfdbt"
      },
      "outputs": [],
      "source": [
        "#2. Direct the output to a new file\n",
        "\n",
        "! zcat cleaned.txt.gz | tr ' ' '\\n' > outputfile.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdbJUPIWeMd5"
      },
      "outputs": [],
      "source": [
        "#Again, check that the file looks as intended.\n",
        "\n",
        "! head outputfile.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYNczsX-z1MI"
      },
      "outputs": [],
      "source": [
        "# 3. Count the lines in the new file\n",
        "\n",
        "#N.B. This is actually also a token count!\n",
        "\n",
        "! cat outputfile.txt | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH4KdjcUD-M0"
      },
      "source": [
        "### Combining `tr` to a frequency list pipeline\n",
        "\n",
        "By combining `tr` to a frequency list pipeline you get a **token frequency list**.\n",
        "\n",
        "In practice, first print the file, then split the tokens one per line and finally, make a frequency list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9CpHoq70DHv"
      },
      "source": [
        "##Now, let's try this.\n",
        "\n",
        "4. Make a token frequency list of the `cleaned.txt.gz` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GMB9fRlDWsZ"
      },
      "outputs": [],
      "source": [
        "# 4. Token frequency list\n",
        "\n",
        "#First split the tokens one per line: tr ' ' '\\n'\n",
        "#then count the frequencies: sort | uniq -c | sort -n\n",
        "\n",
        "! zcat cleaned.txt.gz | tr ' ' '\\n' | sort | uniq -c | sort -rn | head -5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cat outputfile.txt | sort | uniq -c | sort -rn | head -5"
      ],
      "metadata": {
        "id": "UF1yGRlSGEsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQAwWyyPEYzR"
      },
      "source": [
        "### Using `tr` to normalize\n",
        "\n",
        "`tr` can be used to **normalize data**, i.e. changing or removing tokens so that same words are recognized as the same, i.e. that e.g.,\n",
        "  \n",
        "    cat\n",
        "    Cat\n",
        "    cat.\n",
        "    CAT\n",
        "    cat,\n",
        "\n",
        "are recognized as the same word (cat).\n",
        "\n",
        "With `tr` we can\n",
        "\n",
        "* **normalize letters** from upper case to lower case (i.e. replace any upper case letter with a lower case letter):\n",
        "\n",
        "  `tr '[:upper:]' '[:lower:]'`\n",
        "  \n",
        "* **delete numbers** (i.e. replace any number `[0-9]` with a whitespace):\n",
        "\n",
        "  `tr '[0-9]' ' '`\n",
        "* **delete punctuation** (i.e. replace any punctuation `[:punct:]` with a whitespace):\n",
        "\n",
        "  `tr '[:punct:]' ' '`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUGmmoP1OSwP"
      },
      "source": [
        "##Let's practice these.\n",
        "\n",
        "In the `cleaned.txt.gz` file\n",
        "\n",
        "5. **normalize** the text,\n",
        "6. delete the **numbers** and\n",
        "7. delete the **punctuation**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjMmJM3NO-il"
      },
      "outputs": [],
      "source": [
        "#Start by checking the file contents\n",
        "\n",
        "! zcat cleaned.txt.gz | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90qA4uVcEMSs"
      },
      "outputs": [],
      "source": [
        "#5. Normalize - replace upper case with lower case.\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:upper:]' '[:lower:]' | head -20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oaK9Sv2EvPZ"
      },
      "outputs": [],
      "source": [
        "#6. Delete numbers.\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[0-9]' ' ' | head -20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUVI9fHqEyyO"
      },
      "outputs": [],
      "source": [
        "#7. Delete punctuation.\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | head -20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KejzhGp1PiiB"
      },
      "source": [
        "**Note** that the `tr` command **replaces with white space**, and if you have e.g. a year with 4 digits, you get 4 extra white spaces. This leads to empty lines in e.g. frequency lists, but the empty lines can be removed by grepping them.\n",
        "\n",
        "We can **combine** all these to make a cleaned and normalized frequency list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbFCGuSC1M49"
      },
      "source": [
        "##Next, continuing with the file `cleaned.txt.gz`\n",
        "\n",
        "8. a) delete punctuation and numbers, and normalize to lower case\n",
        "      \n",
        "    b) transform to string-per-line format (i.e. word per line)\n",
        "    \n",
        "    c) make a frequency list of the lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq4WfwikE_Wa"
      },
      "outputs": [],
      "source": [
        "#8. a) Clean and normalize the data\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp0n03biF14z"
      },
      "outputs": [],
      "source": [
        "#8. b) Transform to string/token per line\n",
        "\n",
        "#N.B. The empty lines!\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O3yNVTOGT2o"
      },
      "outputs": [],
      "source": [
        "#8. c) Make a frequency list\n",
        "\n",
        "#N.B. The most frequent item is an empty line.\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | sort | uniq -c | sort -rn | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuzyEEFTGYx6"
      },
      "outputs": [],
      "source": [
        "# To get a frequency list without empty lines we need to remove them\n",
        "\n",
        "#egrep -v \"^$\": print lines that do not match ^$ (i.e. print lines that are not empty)\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | egrep -v \"^$\"| sort | uniq -c | sort -rn  | head -20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | egrep -v \"^$\"| sort | uniq -c | sort -rn | egrep \"^the\""
      ],
      "metadata": {
        "id": "SZkgpUeALKHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyDQjOovHKql"
      },
      "source": [
        "### Time out!\n",
        "\n",
        "**New  commands**\n",
        "\n",
        "`git clone`\n",
        "\n",
        "`gzip`\n",
        "\n",
        "`zcat`\n",
        "\n",
        "`tr`\n",
        "\n",
        "**Wildcards** for matching larger groups of characters\n",
        "\n",
        "`[:punct:]`\n",
        "\n",
        "`[0-9]`\n",
        "\n",
        "`[:upper:]`\n",
        "\n",
        "`[:lower:]`\n",
        "\n",
        "(**N.B.** [:punct:] matches **most** punctuation marks, so even if you replace [:punct:] with something else, you might still find some (more specific/unusual) punctuation marks in your data)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}