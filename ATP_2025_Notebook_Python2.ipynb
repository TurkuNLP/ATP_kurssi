{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs8trmxsO75eU/kvzagHNq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/ATP_2025_Notebook_Python2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using OpenAI's API"
      ],
      "metadata": {
        "id": "tCjs3JYTwA9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7LB7xLOv8DA"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "secret_token = \"\" # copy your API key token here!\n",
        "\n",
        "client = OpenAI(api_key=secret_token)\n",
        "model = \"gpt-4o-mini\"\n",
        "\n",
        "\n",
        "def estimate_cost(usage):\n",
        "  # https://platform.openai.com/docs/pricing (accessed 16.12.2025)\n",
        "  input_cost = usage.prompt_tokens / 1000000 * 0.15\n",
        "  output_cost = usage.completion_tokens / 1000000 * 0.60\n",
        "  return input_cost + output_cost\n",
        "\n",
        "def generate(prompt):\n",
        "  chat_completion = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt}], model=model)\n",
        "  cost = estimate_cost(chat_completion.usage)\n",
        "  print(\"User:\", prompt)\n",
        "  print(\"Assistant:\", chat_completion.choices[0].message.content)\n",
        "  print(f\"Cost: {cost:.6f}$\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_prompt = \"Translate into Finnish: Please write your own prompt here!\"\n",
        "generate(my_prompt)"
      ],
      "metadata": {
        "id": "Z57EMePrxqbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing a document collection using LLMs\n",
        "\n",
        "Here is an example how to use LLMs to analyze a document collection. Here we will use few paragraphs from Project Gutenberg books, and translate those into Finnish (or any other language)."
      ],
      "metadata": {
        "id": "l3XHEcLGMb_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To avoid downloading data, I have copied here samples from three books.\n",
        "# Book 1: Frankenstein, Mary Wollstonecraft Shelley: https://www.gutenberg.org/cache/epub/84/pg84.txt (Beginning of Chapter 1)\n",
        "# Book 2: Moby Dick, Herman Melville: https://www.gutenberg.org/cache/epub/2701/pg2701.txt (Beginning of Chapter 1)\n",
        "# Book 3: Pride and Prejudice, Jane Austen: https://www.gutenberg.org/cache/epub/1342/pg1342.txt (Beginning of Chapter 1)\n",
        "\n",
        "books = [\"I am by birth a Genevese, and my family is one of the most distinguished of that republic. My ancestors had been for many years counsellors and syndics, and my father had filled several public situations with honour and reputation. He was respected by all who knew him for his integrity and indefatigable attention to public business. He passed his younger days perpetually occupied by the affairs of his country; a variety of circumstances had prevented his marrying early, nor was it until the decline of life that he became a husband and the father of a family.\",\n",
        "         \"Call me Ishmael. Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. It is a way I have of driving off the spleen and regulating the circulation.\",\n",
        "         \"It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\"]\n",
        "\n",
        "def generate_dataset(prompt, dataset):\n",
        "  total_cost = 0\n",
        "  generated_outputs = []\n",
        "  for document in dataset:\n",
        "    prompt_with_document = prompt + document\n",
        "    chat_completion = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt_with_document}], model=model)\n",
        "    total_cost += estimate_cost(chat_completion.usage)\n",
        "    generated_outputs.append(chat_completion.choices[0].message.content)\n",
        "  print(f\"Generation done, analyzed {len(generated_outputs)} documents.\")\n",
        "  print(f\"Total cost: {total_cost:.6f}$\\n\")\n",
        "  for output in generated_outputs:\n",
        "    print(output, \"\\n\")\n",
        "\n",
        "# call the function\n",
        "my_prompt = \"Translate into Finnish: \"\n",
        "generate_dataset(my_prompt, books)\n"
      ],
      "metadata": {
        "id": "WA3NbXdwNKKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "\n",
        "1) Use `generate(\"Put your own prompt here\")` to test LLM generation. Try it with different prompts and languages. You can ask anything you like.\n",
        "\n",
        "2) Use `generate_dataset(\"Put your own prompt here\", books)` to test how an LLM can be applied to a small dataset of 3 book samples. Note that the function combines the given prompt and each book, so each time the LLM will see your instruction + one book text. Try different prompts. In addition to translation, you can try e.g. \"list all verbs\", \"convert text to uppercase\", \"who is the author of the given book\", \"simplify language\", etc."
      ],
      "metadata": {
        "id": "-2TtSIVmfOxY"
      }
    }
  ]
}