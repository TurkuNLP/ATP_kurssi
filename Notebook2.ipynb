{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO59zNczi6ASP2VQwJ6lCDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/Notebook2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK8j601dEakq"
      },
      "source": [
        "# Notebook 2: more commands, flags (options) and pipes\n",
        "\n",
        "## egrep (or grep)\n",
        "* Matches a pattern on a line and prints it\n",
        "* see http://people.uta.fi/~jm58660/jutut/unix/grep.html \n",
        "* e.g. egrep \"is\" file\n",
        "* Note that capitals and whitespaces count!\n",
        "* So egrep \" is\" file gives a different output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hDMVIHhaDeS"
      },
      "source": [
        "# let's first get the data we had previously\n",
        "! wget https://www.gutenberg.org/cache/epub/20748/pg20748.txt\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWdUHyN6aRi9"
      },
      "source": [
        "! mv pg20748.txt book.txt # let's name this nicer\n",
        "! head book.txt # let's have a look\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VAJnAjraqkb"
      },
      "source": [
        "! egrep \"project\" book.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Olt3H8oazvM"
      },
      "source": [
        "! egrep \"Duck\" book.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syO3NO_SRDlD"
      },
      "source": [
        "## Options / flags\n",
        "\n",
        "* Options are arguments that can be given to Unix commands. These form one of the core elements of Unix command line work.\n",
        "\n",
        "* Options are difficult to remember but you can read them for instance on man pages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOZ0MkEZSA50"
      },
      "source": [
        "! man ls "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUeLK-aRUCXf"
      },
      "source": [
        "* Head -n 15 prints 15 first lines\n",
        "* Tail -n 15 prints 15 last lines\n",
        "* ls -lah prints more information than just ls\n",
        "* egrep -v (reverse) prints lines without a match\n",
        "* egrep -c counts matches\n",
        "* egrep -i ignores case\n",
        "* egrep -B N prints N lines Before\n",
        "* egrep -A N prints N lines After\n",
        "* wc -w prints wordcount\n",
        "* wc -l prints linecount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LNR-oRvm1Up"
      },
      "source": [
        "# let's try a bit!\n",
        "! head -5 book.txt\n",
        "! wc -l book.txt\n",
        "! wc -w book.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNP09g5AnYfx"
      },
      "source": [
        "! egrep -c \"of\" book.txt\n",
        "! egrep -i \"of\" book.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7EWQXx2n9gS"
      },
      "source": [
        "# Flags can also be combined!\n",
        "! egrep -ci \"of\" book.txt\n",
        "! egrep -c \"of\" book.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l6srdjKonG8"
      },
      "source": [
        "### Exercise on flags\n",
        "\n",
        "* Count how many words and lines the Gutenberg book has\n",
        "\n",
        "* First check how the actual text looks like. You remember that with default head and tail we got only the beginning and ending notes, not the actual stories? How could you get a longer chunk of the file?\n",
        "\n",
        "* Let's analyze personal pronouns in the book. How many times the pronoun \"it\" is used? What about the female and male pronouns? How can you use the flags so that you can catch both \"He\" and \"he\"? \n",
        "\n",
        "* (Later we will also learn how to match optional sequences so you can get both \"he\" and \"himself\" to a oneliner, but let's not go there quite yet.)\n",
        "\n",
        "* Create a file where you direct all the counts and their descriptors. For instance, the file could include the following lines:\n",
        "\n",
        "```\n",
        "She appread this many times:\n",
        "15\n",
        "```\n",
        "### Advanced\n",
        "* (You can also combine commands on one line using ;)\n",
        "* (You can assign variables using $:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-DD-gxHt3M4"
      },
      "source": [
        "!wordcount=$(wc -w book.txt) ; echo \"Word count is $wordcount\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFHd6af-ElBx"
      },
      "source": [
        "### Pipes (putket)\n",
        "\n",
        "* You can combine commands with a pipe | (alt gr + the key next to z)\n",
        "* This way the output of the first command goes as input to the next one\n",
        "* cat file.txt | wc -w (is actually the same as just wc -w) # first prints a file, then counts words\n",
        "* cat file.txt | egrep \"is\" # first prints a file, then matches the pattern\n",
        "*  cat file.txt | egrep \"is\"  | wc -w\n",
        "*  cat file.txt | egrep \"is\" | head\n",
        "*  cat file.txt | egrep \"is\" > output.txt\n",
        "* cat file.txt | egrep \"is\" | wc -l\n",
        "* cat file.txt | head -1000 | tail -100 # prints the lines between 900-1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkLHWjUeEoE_"
      },
      "source": [
        "## Exercise \n",
        "\n",
        "* It would be useful to have a look at the actual text in the Gutenberg book, not just the beginning or end. How could you print the lines between 210 and 220? How do they look like?\n",
        "\n",
        "* Can you think of two ways to count the lines that match the word \"Gutenberg\"?\n",
        "* How can you direct to a file the first 5 lines that match \"Gutenberg\"?\n",
        "* Filter away lines that have the word \"gutenberg\" in some form and direct the \"cleaned\" version to a file. Compare this to the original file. How many words or lines did you delete with this filtering?\n",
        "\n",
        "Advanced\n",
        "* Advanced: Can you find egrep options you can use to match entire words?\n",
        "* Make one-liners that print nicely different counts to a file\n",
        "* Btw you can also assign piped commands as variables\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpzbzucr0jw1"
      },
      "source": [
        "!wordcount=$(cat book.txt|egrep -i \"the\" | wc -l) ; echo \"Line count for the is $wordcount\" >> niceoutput.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C97QLjH_G8nO"
      },
      "source": [
        "## Copying a Github repo\n",
        "\n",
        "* Github is a common place to save code and data in NLP.\n",
        "* The repos (directories) can be copied to a local computer programatically\n",
        "* This is quite handy especially with Google colab\n",
        "* The command for the copying is *git clone*, and it should be followed the url \"Code\" link in the green box available at a Git repo\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf7VkIofHS8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb228775-27ab-4e3d-8bfb-4f02ea7ce3f7"
      },
      "source": [
        "! git clone https://github.com/TurkuNLP/ATP_kurssi.git\n",
        "! ls #to check that we got the repo"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ATP_kurssi'...\n",
            "remote: Enumerating objects: 320, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 320 (delta 43), reused 17 (delta 5), pack-reused 233\u001b[K\n",
            "Receiving objects: 100% (320/320), 17.09 MiB | 14.24 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "ATP_kurssi  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xup39u2RXDJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d76bc8-09a4-4f58-a298-1f8e077d0603"
      },
      "source": [
        "# cd will take us to that folder\n",
        "%cd ATP_kurssi/\n",
        "! ls # check that we are at the correct place"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ATP_kurssi\n",
            "Notebook1.ipynb  Notebook2.ipynb  old_versions\tREADME.md  tweets_en_nort.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiBw7F2FHbWW"
      },
      "source": [
        "### Exercise with tweets \n",
        "\n",
        "* The file tweets_en_nort.csv includes tweets\n",
        "* How many are there?\n",
        "* What does the last tweet look like?\n",
        "* Can you think what they discuss? What seems the best way to read the data?\n",
        "* The dataset has a lot of bot-generated tweets that we'd like to filter out. At least one such tweet has the string \"Message of Leader\". Filter those out. How many such tweets were there? How many tweets do you have in the \"cleaned\" dataset after the filtering?\n",
        "* (There can also be other repetitive tweets, if you see any, you can take those away too)\n",
        "\n",
        "* The tweets mention at least France and Paris. Direct these to a separate file, which includes all spelling variants.\n",
        "* Can you find tweets where France or Paris are not capitalized?\n",
        "* There seems to be many news agencies. How many times is FoxNews mentioned? What about other news agencies, can you see any?\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}