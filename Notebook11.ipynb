{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJFyszzblp8z4T9mhOSXX6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/Notebook11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHYppRO8Cycm"
      },
      "source": [
        "## Recap\n",
        "\n",
        "### Exercise 1\n",
        "* Get data https://github.com/TurkuNLP/FinCORE\n",
        "- (If you want non-Finnish data, you can use https://github.com/TurkuNLP/Multilingual-register-corpora)\n",
        "* Read the description on the front page so you know what you are working on\n",
        "* If you want to know more about the classes, see https://turkunlp.org/register-annotation-docs/\n",
        "---\n",
        "First work on the train set of the data\n",
        "* Get a basic idea of the file. How many words in total? How many lines?\n",
        "* How could you print the 10 first lines of the data?\n",
        "* You notice that the data includes also class labels. How could you get those to a separate file? Make a frequency list of the labels\n",
        "* Then create basic statistics of the file: \n",
        "1. How many words alltogether (now that the labels have been excluded)?\n",
        "2. How many unique words?\n",
        "3. What are the most frequent words (e.g. 20)\n",
        "*  To do these, normalize all to lowercase, take all numbers and punctuation \n",
        "\n",
        "---\n",
        "Then\n",
        "* Make a script that does all the steps 1-3 above. See that it works.\n",
        "* Run the script with a for loop to the train, dev and test splits of the data\n",
        "----\n",
        "Third - advanced\n",
        "* Run above information separately for each register class so that you give the class name as an argument to the script\n",
        "* Using a for loop and a list of class labels, you can also do all the classes with one (for loop + script) command\n",
        "\n",
        "For looping through lines of a (label list) file, you can e.g. do\n",
        "\n",
        "```\n",
        "while read p; do\n",
        "  echo \"$p\"\n",
        "done <labels.txt\n",
        "```\n",
        "\n",
        "$p is one line of the file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlt1jBf3zkJc"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "For this, let's use `pb_head.conllu.gz` at\n",
        "\n",
        "```\n",
        "/home/mavela/dataa/syntaksijasennetyt\n",
        "```\n",
        "* Copy to your own home directory\n",
        "* Basic stats (Remember the file format, gz ending and metadata!)\n",
        "** How many words?\n",
        "** How many sentences?\n",
        "** How many documents? Each document starts with `###C:<doc id=`\n",
        "---\n",
        "* Part-of-speech classes are given in column 4. Make a frequency list of the classes\n",
        "* Then take a class and make a cleaned frequency list of the class lemmas \n",
        "---\n",
        "* Make a script that takes as an argument a class and then outputs a frequency list of the class lemmas\n",
        "--\n",
        "* Take one of the most frequent lemmas and make a frequency list of the word forms attached to it.\n",
        "* Make a script to do this"
      ]
    }
  ]
}