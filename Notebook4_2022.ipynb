{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1t1Dirkm0dmv18DF5xU/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/Notebook4_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Today's topics\n",
        "\n",
        "* Cloning Github repos\n",
        "* Gzipped files using `gzip` and `zcat`\n",
        "* Changing characters using `tr`\n",
        "  * Combining `tr` to a frequency list pipeline\n",
        "  * Using `tr` to normalize\n",
        "* Regular expressions"
      ],
      "metadata": {
        "id": "B5iQFtKV0BMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copying a Github repo\n",
        "\n",
        "Github is a common place to save code and data in NLP.\n",
        "The repos (directories) can be copied to a local computer programatically\n",
        "\n",
        "This is quite handy especially with Google colab\n",
        "\n",
        "The command for the copying is `git clone`, and it should be followed the url \"Code\" link in the green box available at a Git repo"
      ],
      "metadata": {
        "id": "ICHHIGKhbr4l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVWyz9Eh04FT"
      },
      "source": [
        "! git clone https://github.com/TurkuNLP/CORE-corpus.git\n",
        "! ls #to check that we got the repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4-bZa7906Pz"
      },
      "source": [
        "# cd will take us to that folder\n",
        "%cd CORE-corpus/\n",
        "! ls # check that we are at the correct place"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic check-ups from gzipped files\n",
        "\n",
        "* `zcat` for printing\n",
        "* `gzip` for producing\n",
        "\n",
        "---\n",
        "* You need to print `gz`-files before you can process them"
      ],
      "metadata": {
        "id": "eMbg83cCb_IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | head # what's in?"
      ],
      "metadata": {
        "id": "o0R7u_8FcpVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head register_label_abbreviations.txt # check what the abbreviations mean"
      ],
      "metadata": {
        "id": "RyA9ygSHBXJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | wc -l #How many lines?"
      ],
      "metadata": {
        "id": "XIyGj3VYcTSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Focus on specific columns\n",
        "\n",
        "* ` cut -f `"
      ],
      "metadata": {
        "id": "_qykucyudjLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | cut -f 3 | head # to focus onthe text"
      ],
      "metadata": {
        "id": "HjCSkWcCd1J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering away the duplicates\n",
        "\n",
        "* Unfortunately, the train file has some duplicates and empty documents. Before we move on, make a file that includes only the text parts of the file, and no duplicates or empty documents\n"
      ],
      "metadata": {
        "id": "hP1eCauOeSIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | wc -l # this many docs in the original"
      ],
      "metadata": {
        "id": "4ez6XC-ffxCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | cut -f 3 | egrep \"^$\" | wc -l # how many empty ones?"
      ],
      "metadata": {
        "id": "geiidh0TB8Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq -c | sort -rn | head -10 # frequency list to see if there are duplicates"
      ],
      "metadata": {
        "id": "5a3RpXoz7XSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | wc -l # how many unique non-empty documents? \n"
      ],
      "metadata": {
        "id": "K-UvG9r6b86c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | cut -f 3 | sort | uniq | gzip > cleaned.txt.gz #Note the gzip command to create a gzipped file!"
      ],
      "metadata": {
        "id": "7lZxTJuM7Cl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing characters\n",
        "\n",
        "Changing characters is often a useful thing to do:\n",
        "* Splitting tokens to one per line (a useful format for Bash)\n",
        "* Splitting to sentences\n",
        "* Normalization --> all to lower case\n",
        "* Deleting punctuation or numbers\n",
        "* `tr` (transform) command can be used for this\n",
        "\n",
        "### Using *tr* to split tokens one per line\n",
        "* Replace whitespace by linebreak `\\n`"
      ],
      "metadata": {
        "id": "3iwz6mRtCLyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz | tr ' ' '\\n' | head # the contents of the first ' ' are transformed to the contents of the second ' '\n"
      ],
      "metadata": {
        "id": "a0mO0GE2CgzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz | head "
      ],
      "metadata": {
        "id": "Y0HVeK_5DBJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz | tr ' ' '\\n' > outputfile.txt # You can direct this to a file\n",
        "! cat outputfile.txt | wc -l # or you can count how many lines (tokens) you have!"
      ],
      "metadata": {
        "id": "_m6Zwm8Sfdbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head outputfile.txt # how did this look like again?"
      ],
      "metadata": {
        "id": "gdbJUPIWeMd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining *tr* to a frequency list pipeline\n",
        "\n",
        "* First split the tokens one per line, then count the frequencies using *sort | uniq -c | sort -n*"
      ],
      "metadata": {
        "id": "KH4KdjcUD-M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz | tr ' ' '\\n' | sort | uniq -c | sort -rn | head -5"
      ],
      "metadata": {
        "id": "6GMB9fRlDWsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using `tr` to normalize\n",
        "\n",
        "* From upper case to lower case: `tr '[:upper:]' '[:lower:]'` # replace any upper case letter with a lower case letter\n",
        "* Deleting numbers: replace any number `[0-9]` with a whitespace\n",
        "* Deleting punctuation: replace any punctuation `[:punct:]` with a whitespace\n"
      ],
      "metadata": {
        "id": "GQAwWyyPEYzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[:upper:]' '[:lower:]' | head -20"
      ],
      "metadata": {
        "id": "90qA4uVcEMSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[0-9]' ' ' | head -20"
      ],
      "metadata": {
        "id": "2oaK9Sv2EvPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | head -20"
      ],
      "metadata": {
        "id": "uUVI9fHqEyyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We can combine all these to make a cleaned and normalized frequency list\n",
        "\n",
        "* Delete punctuation, numbers\n",
        "* Normalize to lowercase\n",
        "* Transform to string-per-line format\n",
        "* Make a frequency list of the lines"
      ],
      "metadata": {
        "id": "hBJ7q5EfFL2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | head"
      ],
      "metadata": {
        "id": "tq4WfwikE_Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | head"
      ],
      "metadata": {
        "id": "Pp0n03biF14z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | sort | uniq -c | sort -rn | head -10"
      ],
      "metadata": {
        "id": "-O3yNVTOGT2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | egrep -v \"^$\"| sort | uniq -c | sort -rn  | head -10 # yet without empty lines"
      ],
      "metadata": {
        "id": "CuzyEEFTGYx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time out!\n",
        "\n",
        "New  commands\n",
        "```\n",
        "* git clone\n",
        "* gzip, zcat\n",
        "* tr\n",
        "```\n",
        "Wildcards for matching larger groups of characters\n",
        "\n",
        "`[:punct:], [0-9], [:upper:], [:lower:]`\n",
        "\n",
        "#### Recap\n",
        "\n",
        "Let's count the most frequent words of one text class from the CORE corpus, *AV*.\n",
        "\n",
        "* Before counting the most frequent words, let's normalize to lowercase and clean punctuation and numbers away\n",
        "* How long in the frequency list do you need to go before you start getting content words? (What do we mean by them?)\n",
        "* What do you think where these texts come from?"
      ],
      "metadata": {
        "id": "IyDQjOovHKql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | egrep -w NA | head # first we need to egrep for the correct labels + texts"
      ],
      "metadata": {
        "id": "le5bhG6zMx7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | egrep -w NA | wc -l # good to check how many we got"
      ],
      "metadata": {
        "id": "Cqy6CdTONPsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | egrep -w NA | cut -f 3 > na.txt # let's then take the third column and direct to a file for simplicity"
      ],
      "metadata": {
        "id": "q5Hd3XfLNbtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat na.txt  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | egrep -v \"^$\" | sort | uniq -c | sort -rn | head -100 | tail -50"
      ],
      "metadata": {
        "id": "9MCyb9q6M6Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular expressions\n",
        "\n",
        "Above, we saw that some expressions - *regular expressions* - can be used to match a larger group of strings\n",
        "* `[:punct:] [:upper:] [:lower:] [0-9]`\n",
        "\n",
        "Note: regexes can vary between languages\n",
        "\n",
        "Some useful *operators*\n",
        "* `^` beginning of line\n",
        "* `$ `end of line\n",
        "* `^$ `empty line (beginning + end without anything between)\n",
        "* `| `alternative, e.g., `\"cat|dog\"`\n",
        "* `[] `group, e.g.` [A-ZÅÄÖa-zåäö] [0-9] [abc]` *any of the characters*\n",
        "* `() `group to form a whole, e.g. `(abc)|(def)`\n",
        "* The same thing can be expressed in many ways, e.g. `[abc]` is the same as `\"a|b|c\"`\n",
        "\n",
        "NOTE: if you want to search for the literal meaning of a regular expression, you need to *escape* it with `\\` \n",
        "\n",
        "These (and more) are listed also here: https://www.guru99.com/linux-regular-expressions.html\n",
        "\n",
        "\n",
        "\n",
        "Let's first make a version of the original file with one token per line"
      ],
      "metadata": {
        "id": "Gty1tNWOQjFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr ' ' '\\n' | egrep -v \"^$\" > one-per-line.txt"
      ],
      "metadata": {
        "id": "ENGAzyUzNtyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat one-per-line.txt | head -5"
      ],
      "metadata": {
        "id": "BOVdYRF6KCjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"any line with the string\"\n",
        "! cat one-per-line.txt | egrep \"is\" | head -4 # any line with the string\n",
        "! echo\n",
        "! echo \"lines strating with the string\"\n",
        "! cat one-per-line.txt | egrep \"^is\" | head -4 # lines starting with is \n",
        "! echo \n",
        "! echo \"lines ending with the string\"\n",
        "! cat one-per-line.txt | egrep \"is$\" |  egrep -v \"^is$\"| head -4 # lines ending with is"
      ],
      "metadata": {
        "id": "-4vJqYUwKh8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat one-per-line.txt | egrep \"ing$\" # any line ending with ing"
      ],
      "metadata": {
        "id": "diutz7MYK_mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat one-per-line.txt | egrep \"^[[:upper:]]\" | head -5 # any line starting with a capital letter"
      ],
      "metadata": {
        "id": "jhCY0BrULhnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat one-per-line.txt | egrep \"[[:punct:]]\" | head -10"
      ],
      "metadata": {
        "id": "uUfxg-D0LyoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat one-per-line.txt | egrep \"^[[:punct:]]\" | head -5 # anything starting with punctuation"
      ],
      "metadata": {
        "id": "11gWRETqOpAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat one-per-line.txt | egrep \"[[:punct:]]$\" | head -5 # anything ending with punctuation"
      ],
      "metadata": {
        "id": "uVan6-W7NYkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat one-per-line.txt | egrep \"^[[:punct:]][A-Z]\" | head -5 # anything starting with punctuation and then a capital letter"
      ],
      "metadata": {
        "id": "WN44y4C2PJer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat  one-per-line.txt | egrep \"[a-zA-Z],[a-zA-Z]\" | head -5 # tokenization mistakes"
      ],
      "metadata": {
        "id": "qMqFOB-YSXQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat  one-per-line.txt | tr '[aeiouy]' ' ' | head -5 # all vowels away"
      ],
      "metadata": {
        "id": "HPy8lUurVf3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A couple more useful operators\n",
        "\n",
        "* `.` any character\n",
        "* `*` 0 times or more\n",
        "* `+ ` 1 time or more\n",
        "* `?`  0 or 1 times\n",
        "\n",
        "Operators can also be combined\n",
        "- `.* ` --> any character 0 times or more\n",
        "- `.?` --> any character 0 or one times\n",
        "- `.+` --> any character 1 or more times\n",
        "- `a+ `--> (the letter) a 1 or more times\n",
        "- `a.*` --> (the letter) a, any character, 1 or more times\n",
        "- `a?.$` -->(the letter) a 0 or 1 times, any character, line end"
      ],
      "metadata": {
        "id": "lrOUAPLaP77K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cat  one-per-line.txt | egrep \"^[A-Z]$\" | head -5 # one-letter lines "
      ],
      "metadata": {
        "id": "HYFJ6nuxPQkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat  one-per-line.txt | egrep \"^[A-Z]+$\" | tail -5 # one or more letters per line"
      ],
      "metadata": {
        "id": "si3xIP_SWLob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat  one-per-line.txt | egrep \"^a.*ing$\" | head #starting with a, ten any character 0 or more times, ing "
      ],
      "metadata": {
        "id": "RBpETUCuWUgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat  one-per-line.txt | egrep \"^A.*'s$\" | uniq | head"
      ],
      "metadata": {
        "id": "V3UkI3A5acXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat  one-per-line.txt  | egrep \"^[[:lower:]]+[[:upper:]]+\" | head -5"
      ],
      "metadata": {
        "id": "_agNhUFga6Ww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}