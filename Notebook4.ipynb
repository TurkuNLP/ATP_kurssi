{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0+B/NWcZAlcdeZTRJl1xk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/Notebook4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZatePoccJwt"
      },
      "source": [
        "## Changing characters\n",
        "\n",
        "Changing characters is often a useful thing to do:\n",
        "* Splitting tokens to one per line (a useful format for Bash)\n",
        "* Splitting to sentences\n",
        "* Normalization --> all to lower case\n",
        "* Deleting punctuation\n",
        "* *tr* (transform) command can be used for this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyDt86wSjEES"
      },
      "source": [
        "# First let's get data: A Christmas Carol by Charles Dickens\n",
        "! wget https://www.gutenberg.org/ebooks/19337.txt.utf-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60fRSVEDjNsD"
      },
      "source": [
        "! ls\n",
        "! mv 19337.txt.utf-8 xmascarol.txt\n",
        "! head -200 xmascarol.txt  | tail -40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gce12mGj4CN"
      },
      "source": [
        "### Using *tr* to split tokens one per line\n",
        "* Replace whitespace by linebreak (\\n)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ezipDDnkdFV"
      },
      "source": [
        "! cat xmascarol.txt | tr ' ' '\\n' # the contents of the first ' ' are transformed to the contents of the second ' '\n",
        "! cat xmascarol.txt | tr ' ' '\\n' > outputfile.txt # You can direct this to a file\n",
        "! cat xmascarol.txt | tr ' ' '\\n' | wc -l # or you can count how many lines (tokens) you have!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnqN87MolGbB"
      },
      "source": [
        "### Combining *tr* to a frequency list pipeline\n",
        "\n",
        "* First split the tokens one per line, then count the frequencies using *sort | uniq -c | sort -n*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igx4Dmq3lbVL"
      },
      "source": [
        "! cat xmascarol.txt | tr ' ' '\\n' | sort | uniq -c | sort -n "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_DATYVzllIp"
      },
      "source": [
        "### Exercise\n",
        "* Download Christmas carol and rename it to something easily conceivable\n",
        "* How many words does the book have?\n",
        "* Using *tr* and *sort uniq* combinations:\n",
        "* How many unique (different) words does the book include?\n",
        "* What are the 20 most frequent tokens of the book?\n",
        "* How many tokens occur only once?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFWvoqgRrf4F"
      },
      "source": [
        "## Using *tr* to normalize\n",
        "\n",
        "* From upper case to lower case: tr '[:upper:]' '[:lower:]' # replace any upper case letter with a lower case letter\n",
        "* Deleting numbers: replace any number ([0-9]) with a whitespace\n",
        "* Deleting punctuation: replace any punctuation ([:punct:]) with a whitespace\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQnMde3g9hjf"
      },
      "source": [
        "! cat xmascarol.txt | tr '[:upper:]' '[:lower:]' | head -20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvDIxRAy9yOm"
      },
      "source": [
        "! cat xmascarol.txt | tr '[0-9]' ' ' | head -20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1x7UV3WT-bw"
      },
      "source": [
        "! cat outputfile.txt | sort | uniq -c | sort -rn | head -5 | tr '[0-9]' ' '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3A87__-T1ol"
      },
      "source": [
        "! cat outputfile.txt | head -30\n",
        "! echo\n",
        "! echo \"And now without punctuation:\"\n",
        "! cat outputfile.txt | tr '[:punct:]' ' '  | head -30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4mNOP3zVcnw"
      },
      "source": [
        "### *tr* and *sort uniq* to compare texts\n",
        "\n",
        "* Combining the commands with pipes lets you turn running texts to cleaned frequency lists of the text words\n",
        "* Steps: \n",
        "** 1) normalize all to lowercase\n",
        "** 2) delete punctuation and numbers (you can do this with separate commands for now)\n",
        "** 3) split tokens to own lines (replace whitespace with a line break)\n",
        "** 4) do a frequency list of the cleaned tokens (lines)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2kSoAQvUiE6"
      },
      "source": [
        "! cat xmascarol.txt | tr '[:upper:]' '[:lower:]'  | tr '[0-9]' ' ' | tr '[:punct:]' ' ' | tr ' ' '\\n' | sort | uniq -c | sort -rn | head -30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ibxz-IdYCit"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Compare *A Christmas Carol* to *The Pickwick Papers* also written by Dickens.\n",
        "\n",
        "The Pickwick Papers is available at https://www.gutenberg.org/files/580/580-0.txt \n",
        "\n",
        "* First look at the data you have. When are the books released to Gutenberg?\n",
        "* Then normalize the data by turning all to lowercase and deleting numbers and punctuation \n",
        "* How many words/tokens do the books include?\n",
        "* How many unique words/tokens do the books include?\n",
        "* Compare (by reading) the 20 most frequent tokens of the books. Do you find any differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92Xb29_mAyu"
      },
      "source": [
        "#### Tip to help comparing files: *paste file1 file2* prints the files side by side. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuxPtvRXl9qS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}