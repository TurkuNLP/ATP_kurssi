{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/ATP_2025_Notebook_4_answers_part_1_and_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5iQFtKV0BMP"
      },
      "source": [
        "# Today's topics\n",
        "\n",
        "I Cloning Github repos\n",
        "\n",
        "II Gzipped files using `gzip` and `zcat`\n",
        "\n",
        "III Changing characters using `tr`\n",
        "  * Combining `tr` to a frequency list pipeline\n",
        "  * Using `tr` to normalize\n",
        "\n",
        "IV Regular expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICHHIGKhbr4l"
      },
      "source": [
        "### I Copying a Github repo\n",
        "\n",
        "Github is a common place to save code and data in NLP. The repos (directories) can be copied to a local computer programatically.\n",
        "\n",
        "This is quite handy especially with Google colab.\n",
        "\n",
        "The command for the copying is `git clone`, and it should be followed the url \"Code\" link in the **green box** available at a Git repo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBBc_B2z96Da"
      },
      "source": [
        "###Let's start by fetching some data from Github.\n",
        "\n",
        "1. Clone the following repo: https://github.com/TurkuNLP/CORE-corpus.git and check that we got it.\n",
        "\n",
        "2. In the repo, there's a folder called CORE-corpus. Go to the folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVWyz9Eh04FT"
      },
      "outputs": [],
      "source": [
        "#1. Clone the repo\n",
        "\n",
        "! git clone https://github.com/TurkuNLP/CORE-corpus.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmwLx7fyaXJr"
      },
      "outputs": [],
      "source": [
        "#Check that we got it\n",
        "\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4-bZa7906Pz"
      },
      "outputs": [],
      "source": [
        "#2. Go to the folder\n",
        "\n",
        "# cd will take us there\n",
        "\n",
        "%cd CORE-corpus/\n",
        "! ls # check that we are at the correct place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMbg83cCb_IW"
      },
      "source": [
        "### II Gzipped files: basic check-ups\n",
        "\n",
        "* `zcat` for printing\n",
        "* `gzip` for producing (writing in a zipped file)\n",
        "\n",
        "---\n",
        "* You need to print `gz` files before you can process **zipped** files\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vDDkEKu-ViH"
      },
      "source": [
        "###Next\n",
        "\n",
        "3. Print the train file within the folder, i.e., always `zcat file.tsv.gz`\n",
        "4. The first column in the file indicates the register label for the text. Check what the abbreviations mean. The CORE-corpus folder contains a file register_label_abbreviations.txt that features all the abbreviations for the register labels.\n",
        "5. Then count the lines (since the data is in the form text per line, you get the number of texts in the file by counting the lines in the file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0R7u_8FcpVp"
      },
      "outputs": [],
      "source": [
        "#3. Print the file\n",
        "! zcat train.tsv.gz | head # what's in the file?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqgMFLBqsqL3"
      },
      "outputs": [],
      "source": [
        "# Register labels are in the first column\n",
        "! zcat train.tsv.gz | cut -f 1 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyA9ygSHBXJR"
      },
      "outputs": [],
      "source": [
        "#4. Check what the labels are.\n",
        "\n",
        "! head register_label_abbreviations.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIyGj3VYcTSy"
      },
      "outputs": [],
      "source": [
        "#5. Line (in this case also text) count\n",
        "\n",
        "! zcat train.tsv.gz | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51dH0EYtUn4D"
      },
      "source": [
        "###Try the commands yourselves.\n",
        "\n",
        "1. Check what the `test` file includes.\n",
        "2. And do the line count for the `test` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KVMTyJ--Uc2"
      },
      "outputs": [],
      "source": [
        "# 1. Check what the *test* file includes\n",
        "! zcat test.tsv.gz | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzk8o-ijAzjA"
      },
      "outputs": [],
      "source": [
        "# 2. And do the line count for the *test* file\n",
        "! zcat test.tsv.gz | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qykucyudjLU"
      },
      "source": [
        "### Focus on specific columns\n",
        "\n",
        "A reminder:\n",
        "\n",
        "` cut -f `\n",
        "\n",
        "Columns in a file can be accessed with the ` cut -f ` command. The **column must be specified** in the command with the flag `-f`. E.g.,\n",
        "\n",
        "`cut -f 5`\n",
        "\n",
        "prints the 5th column in the file.\n",
        "\n",
        "**Note** the white spaces in the command! If they are incorrect, you'll get an error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gno-JVVZwEJF"
      },
      "source": [
        "##Exercise 1\n",
        "\n",
        "1. Print the text column in the `train` file and check that you got it right.\n",
        "2. Check what the different columns have.\n",
        "3. Check the columns in the file `register_label_abbreviations.txt`. What do you get with `cut -f 3`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjCSkWcCd1J2"
      },
      "outputs": [],
      "source": [
        "# 1. Print the text column (the 3rd column) in the train file and check that you got it right.\n",
        "\n",
        "#check with head\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcqDBqEnGlSg"
      },
      "outputs": [],
      "source": [
        "# 2. Check what the different columns have.\n",
        "! zcat train.tsv.gz | cut -f 1 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAbits7VG7j9"
      },
      "outputs": [],
      "source": [
        "# 3. Check the columns in the file register_label_abbreviations.txt. What do you get with cut -f 3?\n",
        "! cat register_label_abbreviations.txt | cut -f 1 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emqO8IV4HJfi"
      },
      "outputs": [],
      "source": [
        "#What happens if you try cut -f 3 on the file register_label_abbreviations.txt?\n",
        "! cat register_label_abbreviations.txt | cut -f 3 | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP1eCauOeSIY"
      },
      "source": [
        "##Exercise 2\n",
        "\n",
        "### Filtering away the duplicates and the empty lines\n",
        "\n",
        "Unfortunately, the train file has some duplicates and empty documents. Before we move on, make a file that includes only the text parts of the file, and no duplicates or empty documents. It's advisable to use e.g. line count and frequency list to check that everything that was supposed to be removed is removed.\n",
        "\n",
        "Make a clean version of the file in which you include **only the texts**.\n",
        "1. Remove **all empty lines** and\n",
        "2. **duplicates**.\n",
        "3. Direct the output in a **new file** called `cleaned.txt.gz`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ez6XC-ffxCV"
      },
      "outputs": [],
      "source": [
        "# 1. First, check how many lines there are in the original file.\n",
        "\n",
        "#N.B. Here, when you count the lines, you get the number of docs/texts\n",
        "\n",
        "! zcat train.tsv.gz | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat train.tsv.gz | cut -f 3 | head"
      ],
      "metadata": {
        "id": "lKIBRmJUC8a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geiidh0TB8Cr"
      },
      "outputs": [],
      "source": [
        "#Then, check how many empty lines (in the text column) the file includes.\n",
        "\n",
        "#cut -f 3: access the text column\n",
        "#egrep \"^$\": get the empty lines (^ line start, $ line end)\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep \"^$\" | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-GRa90-FbfK"
      },
      "outputs": [],
      "source": [
        "#Check that all the empty lines are removed (count the remaining lines after the removal of the empty ones).\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a3RpXoz7XSB"
      },
      "outputs": [],
      "source": [
        "# 2. Check the duplicates in the file.\n",
        "\n",
        "#sort: sort the lines alphabetically\n",
        "#uniq -c: counts the number of consequtive duplicate lines\n",
        "#sort -rn: n sorts according to numbers, r sorts in reverse order (descending order)\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq -c | sort -rn | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-UvG9r6b86c"
      },
      "outputs": [],
      "source": [
        "#Count how many unique non-empty docs there are in the file.\n",
        "\n",
        "#sort: sorts alphabetically\n",
        "#uniq: prints only once each (duplicate) line\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | wc -l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lZxTJuM7Cl6"
      },
      "outputs": [],
      "source": [
        "# 3. Direct the output to a new file.\n",
        "\n",
        "#gzip: create a gzipped file\n",
        "\n",
        "! zcat train.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | gzip > cleaned.txt.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYSBQ8YixrXL"
      },
      "outputs": [],
      "source": [
        "# Check that the new file exists.\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1SKwp1exwtq"
      },
      "outputs": [],
      "source": [
        "# Check the file contents.\n",
        "! zcat cleaned.txt.gz | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prPtXTuSVmBH"
      },
      "source": [
        "**EXTRA TIME LEFT?**\n",
        "\n",
        "Clean the test file as above (i.e. do all the same things for the test file as for the train file). Remember to check the output of each pipe so you can be sure that you end up with the intended final output. Finally, direct the output of the cleaned test file to a new file called `cleaned_test_file.txt.gz`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7d_6tzwKg5u"
      },
      "outputs": [],
      "source": [
        "#Clean the test file.\n",
        "\n",
        "! zcat test.tsv.gz | cut -f 3 | head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | wc -l"
      ],
      "metadata": {
        "id": "9dsodSMXO0pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | egrep \"^$\" | wc -l"
      ],
      "metadata": {
        "id": "XJ1umw2BOhAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | egrep -v \"^$\" | wc -l"
      ],
      "metadata": {
        "id": "QXJFAgUqOxuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | head"
      ],
      "metadata": {
        "id": "D_1xv5Z0OuFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat test.tsv.gz | cut -f 3 | egrep -v \"^$\" | sort | uniq | wc -l"
      ],
      "metadata": {
        "id": "nDEcewulO9-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iwz6mRtCLyZ"
      },
      "source": [
        "### III Changing characters\n",
        "\n",
        "Changing characters is often a useful thing to do:\n",
        "* **Splitting** tokens to one per line (a useful format for Bash), i.e. the format is **word per line**\n",
        "* Splitting **to sentences**\n",
        "* **Normalization** (i.e. all to lower case)\n",
        "* **Deleting** punctuation or numbers\n",
        "\n",
        "### Using `tr` to split tokens one per line\n",
        "* `tr` refers to transform\n",
        "* use **single quotation** marks to indicate **what is transformed** (within first single quotation marks) and **to what** (within the second single quotation marks)\n",
        "\n",
        "  e.g. `tr ' ' '\\n'`\n",
        "\n",
        "  transforms white space (' ') to a line break ('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r97IcEtrHUtS"
      },
      "source": [
        "##Let's try this.\n",
        "1. **Split the tokens** one per line in the file `cleaned.txt.gz`\n",
        "2. **Direct the output** (the word-per-line output) to `outputfile.txt`\n",
        "3. **Count the lines** in the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0mO0GE2CgzM"
      },
      "outputs": [],
      "source": [
        "#1. Word per line: the contents of the first ' ' is transformed to the contents of the second ' '\n",
        "#In the present context this means that each white space is transformed to line break\n",
        "\n",
        "# ' ' refers to white space\n",
        "# '\\n' refers to new line\n",
        "\n",
        "! zcat cleaned.txt.gz | tr ' ' '\\n' | head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0HVeK_5DBJN"
      },
      "outputs": [],
      "source": [
        "#Compare to the original file\n",
        "\n",
        "! zcat cleaned.txt.gz | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m6Zwm8Sfdbt"
      },
      "outputs": [],
      "source": [
        "#2. Direct the output to a new file\n",
        "\n",
        "! zcat cleaned.txt.gz | tr ' ' '\\n' > outputfile.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdbJUPIWeMd5"
      },
      "outputs": [],
      "source": [
        "#Again, check that the file looks as intended.\n",
        "\n",
        "! head outputfile.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYNczsX-z1MI"
      },
      "outputs": [],
      "source": [
        "# 3. Count the lines in the new file\n",
        "\n",
        "#N.B. This is actually also a token count!\n",
        "\n",
        "! cat outputfile.txt | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH4KdjcUD-M0"
      },
      "source": [
        "### Combining `tr` to a frequency list pipeline\n",
        "\n",
        "By combining `tr` to a frequency list pipeline you get a **token frequency list**.\n",
        "\n",
        "In practice, first print the file, then split the tokens one per line and finally, make a frequency list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9CpHoq70DHv"
      },
      "source": [
        "##Now, let's try this.\n",
        "\n",
        "4. Make a token frequency list of the `cleaned.txt.gz` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GMB9fRlDWsZ"
      },
      "outputs": [],
      "source": [
        "# 4. Token frequency list\n",
        "\n",
        "#First split the tokens one per line: tr ' ' '\\n'\n",
        "#then count the frequencies: sort | uniq -c | sort -n\n",
        "\n",
        "! zcat cleaned.txt.gz | tr ' ' '\\n' | sort | uniq -c | sort -rn | head -5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cat outputfile.txt | sort | uniq -c | sort -rn | head -5"
      ],
      "metadata": {
        "id": "UF1yGRlSGEsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQAwWyyPEYzR"
      },
      "source": [
        "### Using `tr` to normalize\n",
        "\n",
        "`tr` can be used to **normalize data**, i.e. changing or removing tokens so that same words are recognized as the same, i.e. that e.g.,\n",
        "  \n",
        "    cat\n",
        "    Cat\n",
        "    cat.\n",
        "    CAT\n",
        "    cat,\n",
        "\n",
        "are recognized as the same word (cat).\n",
        "\n",
        "With `tr` we can\n",
        "\n",
        "* **normalize letters** from upper case to lower case (i.e. replace any upper case letter with a lower case letter):\n",
        "\n",
        "  `tr '[:upper:]' '[:lower:]'`\n",
        "  \n",
        "* **delete numbers** (i.e. replace any number `[0-9]` with a whitespace):\n",
        "\n",
        "  `tr '[0-9]' ' '`\n",
        "* **delete punctuation** (i.e. replace any punctuation `[:punct:]` with a whitespace):\n",
        "\n",
        "  `tr '[:punct:]' ' '`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUGmmoP1OSwP"
      },
      "source": [
        "##Let's practice these.\n",
        "\n",
        "In the `cleaned.txt.gz` file\n",
        "\n",
        "5. **normalize** the text,\n",
        "6. delete the **numbers** and\n",
        "7. delete the **punctuation**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjMmJM3NO-il"
      },
      "outputs": [],
      "source": [
        "#Start by checking the file contents\n",
        "\n",
        "! zcat cleaned.txt.gz | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90qA4uVcEMSs"
      },
      "outputs": [],
      "source": [
        "#5. Normalize - replace upper case with lower case.\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:upper:]' '[:lower:]' | head -20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oaK9Sv2EvPZ"
      },
      "outputs": [],
      "source": [
        "#6. Delete numbers.\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[0-9]' ' ' | head -20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUVI9fHqEyyO"
      },
      "outputs": [],
      "source": [
        "#7. Delete punctuation.\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | head -20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KejzhGp1PiiB"
      },
      "source": [
        "**Note** that the `tr` command **replaces with white space**, and if you have e.g. a year with 4 digits, you get 4 extra white spaces. This leads to empty lines in e.g. frequency lists, but the empty lines can be removed by grepping them.\n",
        "\n",
        "We can **combine** all these to make a cleaned and normalized frequency list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbFCGuSC1M49"
      },
      "source": [
        "##Next, continuing with the file `cleaned.txt.gz`\n",
        "\n",
        "8. a) delete punctuation and numbers, and normalize to lower case\n",
        "      \n",
        "    b) transform to string-per-line format (i.e. word per line)\n",
        "    \n",
        "    c) make a frequency list of the lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq4WfwikE_Wa"
      },
      "outputs": [],
      "source": [
        "#8. a) Clean and normalize the data\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp0n03biF14z"
      },
      "outputs": [],
      "source": [
        "#8. b) Transform to string/token per line\n",
        "\n",
        "#N.B. The empty lines!\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O3yNVTOGT2o"
      },
      "outputs": [],
      "source": [
        "#8. c) Make a frequency list\n",
        "\n",
        "#N.B. The most frequent item is an empty line.\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | sort | uniq -c | sort -rn | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuzyEEFTGYx6"
      },
      "outputs": [],
      "source": [
        "# To get a frequency list without empty lines we need to remove them\n",
        "\n",
        "#egrep -v \"^$\": print lines that do not match ^$ (i.e. print lines that are not empty)\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | egrep -v \"^$\"| sort | uniq -c | sort -rn  | head -20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zcat cleaned.txt.gz  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | egrep -v \"^$\"| sort | uniq -c | sort -rn | egrep \"^the\""
      ],
      "metadata": {
        "id": "SZkgpUeALKHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyDQjOovHKql"
      },
      "source": [
        "### Time out!\n",
        "\n",
        "**New  commands**\n",
        "\n",
        "`git clone`\n",
        "\n",
        "`gzip`\n",
        "\n",
        "`zcat`\n",
        "\n",
        "`tr`\n",
        "\n",
        "**Wildcards** for matching larger groups of characters\n",
        "\n",
        "`[:punct:]`\n",
        "\n",
        "`[0-9]`\n",
        "\n",
        "`[:upper:]`\n",
        "\n",
        "`[:lower:]`\n",
        "\n",
        "(**N.B.** [:punct:] matches **most** punctuation marks, so even if you replace [:punct:] with something else, you might still find some (more specific/unusual) punctuation marks in your data)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P4vdcZr14RM"
      },
      "source": [
        "##Exercise 3\n",
        "\n",
        "#### **Recap**\n",
        "\n",
        "Let's count the most frequent words of one text class from the CORE corpus, *NA*.\n",
        "\n",
        "1. Grab the **NA texts** and direct them to a folder called `na.txt`\n",
        "2. Before counting the most frequent words, let's **normalize** to lower case and **remove** punctuation and numbers.\n",
        "3. Make a **frequency list** of the words in the file. How long in the frequency list do you need to go before you start getting content words? (What do we mean by them?)\n",
        "4. Where do you think these texts come from?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le5bhG6zMx7o"
      },
      "outputs": [],
      "source": [
        "#1. Grab the NA texts and direct them to a folder called na.txt\n",
        "\n",
        "# first we need to egrep for the correct labels + texts\n",
        "\n",
        "#N.B. egrep -w : match only whole words (i.e. prints lines with the whole word)\n",
        "# egrep -w \"cat\" matches \"cat\", but not \"cats\", \"catering\" or \"vacation\" (egrep \"cat\" would match these, too)\n",
        "\n",
        "#! zcat train.tsv.gz | egrep -w NA | head  # notice that this line would also work without quotes around NA, but it is good practice to use quotes anyway\n",
        "! zcat train.tsv.gz | egrep -w \"NA\" | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqy6CdTONPsA"
      },
      "outputs": [],
      "source": [
        "# good to check how many we got\n",
        "\n",
        "! zcat train.tsv.gz | egrep -w NA | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5Hd3XfLNbtB"
      },
      "outputs": [],
      "source": [
        "#Then take the texts only and check that the output is correct\n",
        "\n",
        "#cut -f 3 takes the third column with the text\n",
        "\n",
        "! zcat train.tsv.gz | egrep -w NA | cut -f 3 | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz8gsUn6BMtd"
      },
      "outputs": [],
      "source": [
        "#Finally, direct the NA texts to a new file\n",
        "\n",
        "! zcat train.tsv.gz | egrep -w NA | cut -f 3 > na.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDGqDcML2cxl"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFgHTX092d_9"
      },
      "outputs": [],
      "source": [
        "! cat na.txt | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MCyb9q6M6Po"
      },
      "outputs": [],
      "source": [
        "#2. Normalize the data and remove punctuation and numbers\n",
        "\n",
        "#It's a good idea to check that everything looks as it should\n",
        "#Sometimes it might be useful to check what the command does after each pipe to make sure you get the intended output in the end\n",
        "#Checking is a way to avoid mistakes (or if you have a mistake in the final output, it's a good idea to check each pipe's output)\n",
        "\n",
        "! cat na.txt  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | egrep -v \"^$\" | head -50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLIeEnLjkJN3"
      },
      "outputs": [],
      "source": [
        "#3. Frequency list\n",
        "\n",
        "#head -100 | tail -50: first print the top 100 words, then the last 50 (the tail with 50 lines) from these top 100\n",
        "\n",
        "! cat na.txt  | tr '[:punct:]' ' ' | tr '[0-9]' ' ' | tr '[:upper:]' '[:lower:]' | tr ' ' '\\n' | egrep -v \"^$\" | sort | uniq -c | sort -rn | head -100 | tail -50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gty1tNWOQjFP"
      },
      "source": [
        "## IV Regular expressions\n",
        "\n",
        "Above, we saw that **regular expressions** can be used to match a larger group of strings\n",
        "* `[:punct:]`\n",
        "* `[:upper:] [:lower:]`\n",
        "* `[0-9]`\n",
        "\n",
        "**Note1**: regexes can vary between languages\n",
        "\n",
        "**Note2**: the letters **å**, **ä**, **ö** are not recognized e.g. by `[:upper:] [:lower:]`\n",
        "\n",
        "Some useful **operators**\n",
        "* `^` beginning of line\n",
        "* `$` end of line\n",
        "* `^$` empty line (beginning + end without anything inbetween)\n",
        "* `|` alternative, e.g., `\"cat|dog\"`\n",
        "* `[]` group, e.g.`[A-ZÅÄÖa-zåäö]`, `[0-9]`, `[abc]` ***any** of the characters*\n",
        "* `()` group to form a whole, e.g. `(abc)|(def)`\n",
        "* The same thing can be expressed in many ways, e.g. `[abc]` is the same as `\"a|b|c\"`\n",
        "\n",
        "**NOTE**: if you want to search for the literal meaning of a regular expression, you need to **escape** it with `\\`\n",
        "\n",
        "e.g. `egrep '\\$|€|£'`\n",
        "\n",
        "These (and more) are listed also here: https://www.guru99.com/linux-regular-expressions.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-X5RLXHnjU2"
      },
      "source": [
        "##Practicing regex\n",
        "\n",
        "1. Let's first make a version of the original file with one token per line. Direct the new version to the file `one-per-line.txt`\n",
        "\n",
        "\n",
        "2. In this new file, grep the lines that\n",
        "  \n",
        "    a) match the string \"is\"\n",
        "  \n",
        "    b) start with \"is\"\n",
        "  \n",
        "    c) end with \"is\"\n",
        "\n",
        "3. Grep the lines\n",
        "\n",
        "    a) ending with \"ing\"\n",
        "  \n",
        "    b) starting with a capital letter\n",
        "\n",
        "    c) with any punctuation mark\n",
        "\n",
        "    d) beginning with a punctuation mark\n",
        "\n",
        "    e) ending with a punctuation mark\n",
        "\n",
        "    f) begining with a punctuation mark followed by a capital letter\n",
        "\n",
        "4. Find tokenization mistakes.\n",
        "\n",
        "5. Remove all vowels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4XtGeY00Krq"
      },
      "outputs": [],
      "source": [
        "# Check the cleaned.txt.gz file\n",
        "\n",
        "! zcat cleaned.txt.gz | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12riJ4VJ0Sa7"
      },
      "outputs": [],
      "source": [
        "#1. Make a token per line file; start by checking the output\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr ' ' '\\n' | egrep -v \"^$\" | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENGAzyUzNtyf"
      },
      "outputs": [],
      "source": [
        "#Direct the output to a new file\n",
        "\n",
        "! zcat cleaned.txt.gz  | tr ' ' '\\n' | egrep -v \"^$\" > one-per-line.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byGAue5s5a2j"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOVdYRF6KCjV"
      },
      "outputs": [],
      "source": [
        "#Check the file contents\n",
        "\n",
        "! cat one-per-line.txt | head -5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4vJqYUwKh8b"
      },
      "outputs": [],
      "source": [
        "#2. a) Lines with \"is\"\n",
        "\n",
        "! echo \"any line with the string\"\n",
        "! cat one-per-line.txt | egrep \"is\" | head -4 # any line with the string\n",
        "! echo\n",
        "\n",
        "#2. b) Lines starting with \"is\"\n",
        "\n",
        "! echo \"lines starting with the string\"\n",
        "! cat one-per-line.txt | egrep \"^is\" | head -4 # lines starting with is\n",
        "! echo\n",
        "\n",
        "#2. c) Lines that end with \"is\"\n",
        "\n",
        "! echo \"lines ending with the string\"\n",
        "! cat one-per-line.txt | egrep \"is$\" |  egrep -v \"^is$\"| head -4 # lines ending with is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diutz7MYK_mY"
      },
      "outputs": [],
      "source": [
        "#3. a) Lines that end with \"ing\"\n",
        "\n",
        "! cat one-per-line.txt | egrep \"ing$\" | head -20 # any line ending with ing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhCY0BrULhnQ"
      },
      "outputs": [],
      "source": [
        "#3. b) Lines that start with a capital letter\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^[[:upper:]]\" | head -5 # any line starting with a capital letter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUfxg-D0LyoF"
      },
      "outputs": [],
      "source": [
        "#3. c) Lines with a punctuation mark\n",
        "\n",
        "! cat one-per-line.txt | egrep \"[[:punct:]]\" | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11gWRETqOpAp"
      },
      "outputs": [],
      "source": [
        "#3. d) Lines that begin with a punctuation mark\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^[[:punct:]]\" | head -5 # anything starting with punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVan6-W7NYkD"
      },
      "outputs": [],
      "source": [
        "#3. e) Lines that end with a punctuation mark\n",
        "\n",
        "! cat one-per-line.txt | egrep \"[[:punct:]]$\" | head -5 # anything ending with punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN44y4C2PJer"
      },
      "outputs": [],
      "source": [
        "#3. f) Lines that begin with a punctuation mark followed by a capital letter\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^[[:punct:]][A-Z]\" | head -5 # anything starting with punctuation and then a capital letter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMqFOB-YSXQl"
      },
      "outputs": [],
      "source": [
        "#4. Find tokenization mistakes (i.e. not tokenized words)\n",
        "\n",
        "#egrep \"[a-zA-Z],[a-zA-Z]\" matches lines in which any letter is followed by a comma (no white space inbetween)\n",
        "#followed by any letter (no white space after the comma)\n",
        "\n",
        "! cat one-per-line.txt | egrep \"[a-zA-Z],[a-zA-Z]\" | head -5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPy8lUurVf3k"
      },
      "outputs": [],
      "source": [
        "#5. Remove all vowels\n",
        "\n",
        "! cat one-per-line.txt | tr '[aeiouy]' ' ' | head -5 # all vowels away"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrOUAPLaP77K"
      },
      "source": [
        "### A couple more useful operators\n",
        "\n",
        "* `.` any character\n",
        "* `*` 0 times or more (i.e. present or absent)\n",
        "* `+ ` 1 time or more\n",
        "* `?`  0 or 1 time\n",
        "\n",
        "Operators can also be **combined**\n",
        "- `.* ` any character 0 time or more\n",
        "- `.?` any character 0 or one time\n",
        "- `.+` any character 1 or more times\n",
        "- `a+ ` (the letter) *a* 1 or more times\n",
        "- `a.*` (the letter) *a* followed by any character, 1 or more times\n",
        "- `a?.$` (the letter) *a* 0 or 1 time followed by any character and line end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0J7wZPF4dpX"
      },
      "source": [
        "# Exercise 4\n",
        "\n",
        "In the file `one-per-line.txt` grep lines\n",
        "\n",
        "1. with only one capital letter and nothing else\n",
        "2. with one or more capital letters but nothing else\n",
        "3. starting with the letter \"a\" followed by any character 0 or more times, and ending with ing\n",
        "4. with proper nouns starting with A in the possessive form, i.e. words starting with the capital A followed by any character 0 or more times followed by 's and line end\n",
        "5. with words in the form wOrd, wORD, woRD, or worD, i.e. lines that start with one or more lower case letter(s) followed by one or more capital letter(s)\n",
        "\n",
        "Let's do these first exercises **together**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYFJ6nuxPQkN"
      },
      "outputs": [],
      "source": [
        "# 1. Lines with only one capital letter and nothing else\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^[A-Z]$\" | head -5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si3xIP_SWLob"
      },
      "outputs": [],
      "source": [
        "# 2. Lines with one or more capital letters but nothing else\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^[A-Z]+$\" | tail -5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBpETUCuWUgc"
      },
      "outputs": [],
      "source": [
        "# 3. Lines starting with the letter \"a\" followed by any character 0 or more times, and ending with ing\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^a.*ing$\" | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3UkI3A5acXj"
      },
      "outputs": [],
      "source": [
        "# 4. Lines with proper nouns on A in the possessive form, i.e. words starting with a capital A\n",
        "# followed by any character 0 or more times followed by 's and line end)\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^A.*'s$\" | uniq | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_agNhUFga6Ww"
      },
      "outputs": [],
      "source": [
        "# 5. Lines with words in the form wOrd, wORD, woRD, worD\n",
        "# i.e. lines that start with one or more lower case letter(s) followed by one or more capital letter(s)\n",
        "\n",
        "! cat one-per-line.txt  | egrep \"^[[:lower:]]+[[:upper:]]+\" | head -5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNvo0xHcC5_Q"
      },
      "source": [
        "##**N.B.**\n",
        "\n",
        "`.` stands for any **character**; i.e., not only letters but also e.g. numbers\n",
        "\n",
        "`[a-z]` stands for *any* lower case **letter**\n",
        "\n",
        "`[A-Z]` stands for *any* upper case **letter**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA-XAqXY6teB"
      },
      "source": [
        "###Continue with the following exercises\n",
        "\n",
        "In the file `one-per-line.txt` grep lines\n",
        "\n",
        "6. with the word \"cat\" ending with punctuation mark(s)\n",
        "7. with the word \"cat\" ending with just one punctuation mark\n",
        "8. with compound words with a hyphen, e.g. \"co-operate\"\n",
        "9. that end in full stop\n",
        "10. written fully in capitals\n",
        "11. starting with punctuation\n",
        "12. with words only (i.e. lines with only letters)\n",
        "\n",
        "13. Can you tell what the difference is between these two lines:\n",
        "\n",
        "    `egrep \"^[[:punct:]]$`\n",
        "\n",
        "    `egrep \"^[[:punct:]]+$`\n",
        "\n",
        "14. Can you tell what the difference is between these two lines:\n",
        "\n",
        "    `egrep \"^.[[:punct:]].[[:punct:]].`\n",
        "\n",
        "    `egrep \"^[a-z][[:punct:]][a-z][[:punct:]][a-z]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "3cG9cJm79Nhj"
      },
      "outputs": [],
      "source": [
        "# 6. Lines with the word \"cat\" ending with punctuation mark(s)\n",
        "\n",
        "! cat one-per-line.txt  | egrep \"^cat[[:punct:]]\" | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n8qTo_wq7Czg"
      },
      "outputs": [],
      "source": [
        "# 7. Lines with the word \"cat\" ending with just one punctuation mark\n",
        "\n",
        "! cat one-per-line.txt  | egrep \"^cat[[:punct:]]$\" | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a1_GPHrL7KS4"
      },
      "outputs": [],
      "source": [
        "# 8. Lines with compound words with a hyphen, e.g. \"co-operate\"\n",
        "\n",
        "! cat one-per-line.txt  | egrep \"^.+-.+$\" | head -10  # this will match also e.g. 123-123\n",
        "! echo '----------------------------------------'\n",
        "! cat one-per-line.txt  | egrep \"^[a-zA-Z]+-[a-zA-Z]+$\" | head -10  # this will only match words that consists of letters, but it even omits words ending in commas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KOXHMkVD7ns4"
      },
      "outputs": [],
      "source": [
        "# 9. Lines that end in full stop\n",
        "\n",
        "! cat one-per-line.txt  | egrep \"^.+\\.$\" | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aWsSmSnp8OPs"
      },
      "outputs": [],
      "source": [
        "# 10. Lines written fully in capitals\n",
        "# (The output might make more sense if you remove 'I')\n",
        "\n",
        "! cat one-per-line.txt  | egrep \"^[[:upper:]]+$\" | egrep -v \"^I$\" | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ru8NyOZ09gl5"
      },
      "outputs": [],
      "source": [
        "# 11. Lines starting with punctuation\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^[[:punct:]]+\" | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8v4KuVJ-DkgC"
      },
      "outputs": [],
      "source": [
        "# 12. Lines with words only (i.e. lines with only letters)\n",
        "\n",
        "! cat one-per-line.txt | egrep '^[a-zA-Z]+$' | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vBmblmQ5-BfT"
      },
      "outputs": [],
      "source": [
        "# 13. Can you tell what the difference is between these two lines:\n",
        "# egrep \"^[[:punct:]]$\n",
        "# egrep \"^[[:punct:]]+$\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^[[:punct:]]$\" | tail -10  # finds lines with just one punctuation\n",
        "! echo '----------------------------------'\n",
        "! cat one-per-line.txt | egrep \"^[[:punct:]]+$\" | tail -10  # finds lines with one or more punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BNj8DzfBIL2B"
      },
      "outputs": [],
      "source": [
        "# 14. Can you tell what the difference is between these two lines:\n",
        "# egrep \"^.[[:punct:]].[[:punct:]].\"\n",
        "# egrep \"^[a-z][[:punct:]][a-z][[:punct:]][a-z]\"\n",
        "\n",
        "! cat one-per-line.txt | egrep \"^.[[:punct:]].[[:punct:]].\" | head -10  # one character + one punct + one character + one punct + one character\n",
        "! echo '-----------------------------------'\n",
        "! cat one-per-line.txt | egrep \"^[a-z][[:punct:]][a-z][[:punct:]][a-z]\" | head -10  # one lower case letter + one punct + one lower case letter + one punct + one ower case letter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpBl_2RQEU73"
      },
      "source": [
        "# **In this Notebook we covered the following**\n",
        "\n",
        "`git clone`\n",
        "\n",
        "`gzip`\n",
        "\n",
        "`zcat`\n",
        "\n",
        "`tr`\n",
        "\n",
        "**Regular expressions, a.k.a. regex** such as\n",
        "\n",
        "`[[:punct:]]`\n",
        "\n",
        "`[0-9]`\n",
        "\n",
        "`.`\n",
        "\n",
        "`*`\n",
        "\n",
        "`^`\n",
        "\n",
        "`$`\n",
        "\n",
        "and the combination of these, e.g.:\n",
        "\n",
        "`^a?.$`\n",
        "\n",
        "`^a.*ing$`\n",
        "\n",
        "`^[[:lower:]]+[[:upper:]]+`\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}