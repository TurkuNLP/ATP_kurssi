{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnj/YXJNXnQDvYXNd398No",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/Notebook8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPEsOWiSpYOz"
      },
      "source": [
        "## Running python from command line\n",
        "\n",
        "```\n",
        "python3 program.py\n",
        "cat input.txt | python3 program.py\n",
        "```\n",
        "* You can find `print_sent.py` in the same folder\n",
        "`/home/mavela/dataa/syntaksijasennetyt`\n",
        "\n",
        "* This takes input from standard input so from pipe\n",
        "* As argument, you should give which column to focus\n",
        "\n",
        "`zcat suomi24.conllu.gz | python3 print_sent.py LEMMA | less`\n",
        "\n",
        "* The columns in the CoNLL format were\n",
        "\n",
        "`ID WORD LEMMA POS POS MORFOLOGY HEAD DEPREL MISC MISC`\n",
        "\n",
        "* Then the script prints sentence at a time the words and the LEMMAs as specified in the argument"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXO085OIsm-t"
      },
      "source": [
        "### Exercise on conllu datasets and treebanks\n",
        "\n",
        "* Choose a treebank from Universal dependencies website https://universaldependencies.org/#download\n",
        "* Download a treebank or at least its trainset using `git clone`\n",
        "* Let's get some basic stats. You can focus on the train file.\n",
        "**  How many words does the data have?\n",
        "**  And how many sentences?\n",
        "**  How many unique words? (normalize to lower case)\n",
        "* Remember to exclude metadata!\n",
        "---\n",
        "* Then about the lexical characteristics of the dataset\n",
        "**  How many different lemmas does the data have? How many of these appear only once?\n",
        "**  ADVANCED: you can see that the list has a lot of non-alphabet characters. Think how you could filter those away? Any difficult cases? \n",
        "** Too agressive filtering may delete useful words. Note: there's no perfect answer to this!\n",
        "**  Make a frequency list of the most frequent lemmas in the data. Make sure all are in lower case and exclude at least punctuation. What are the most frequent words? ADVANCED: any other classes you could exclude to reduce noise?\n",
        "\n",
        "--------------\n",
        "* Stop words are in NLP considered as words that don't have much content value, such as pronouns or conjunctions. This can be seen in the lemma list. \n",
        "** Let's make a frequency list which focuses on content words and excludes stop words. We could count as those nouns (NOUN), verbs (VERB), adjectives (ADJ) and adverbs (ADV).\n",
        "**  How does the lemma list look like if we include only those?\n",
        "**  Then the other way around. What are the most frequent nouns, adjectives and verbs? \n",
        "------\n",
        "*   `Get print_sent.py` and `print_some_sent.py` to your working directory, either by copying from `/home/mavela/dataa/syntaksijasennetyt`or using `git clone`.\n",
        "**  Proper nouns are tagged with PROPN. How many different proper nouns does the data have? What are the most frequent ones?\n",
        "**  `Run print_sent.py` to have a look at some sentences and their analyses\n",
        "**  Then `run print_some_sent.py` by focusing on UPOS and PROPN (proper nouns)\n"
      ]
    }
  ]
}