{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSFDIlFxQH28ues57iFUdp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/Notebook5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugcHhM8Kw6cq"
      },
      "source": [
        "## Regular expressions\n",
        "\n",
        "\n",
        "* We saw last time that some expressions can be used to match a larger group of strings\n",
        "** [:punct:] [:upper:] [:lower:] [0-9]\n",
        "\n",
        "* Note: regexes can vary between languages\n",
        "\n",
        "\n",
        "Some useful *operators*\n",
        "* ^ beginning of line\n",
        "* \\$ end of line\n",
        "* ^$ empty line (beginning + end without anything between)\n",
        "* . any character\n",
        "* | alternative, e.g., \"cat|dog\"\n",
        "* \\*  match previous character 0 times or more\n",
        "* \\+ match previous character 1 time or more\n",
        "* ? match previous character 0 or 1 times\n",
        "* [] group, e.g. [A-ZÅÄÖa-zåäö], [0-9], [abc] *any of the characters*\n",
        "* () group to form a whole, e.g. (abc)|(def)\n",
        "* The same thing can be expressed in many ways, e.g. [abc] is the same as \"a|b|c\"\n",
        "\n",
        "Operators can also be combined\n",
        "- .*  --> any character (.) 0 times or more (*)\n",
        "-- .? --> any character 0 or one times\n",
        "-- .+ --> any character 1 or more times\n",
        "-- a+ --> (the letter) a 1 or more times\n",
        "-- a.* --> (the letter) a, any character(.) 1 or more times\n",
        "-- a?.$ -->(the letter) a 0 or 1 times, any character, line end\n",
        "\n",
        "NOTE: if you want to search for the literal meaning of a regular expression, you need to *escape* it with \\ \n",
        "\n",
        "These (and more) are listed also here: https://www.guru99.com/linux-regular-expressions.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvK2JbUT6eQr"
      },
      "source": [
        "! git clone https://github.com/TurkuNLP/ATP_kurssi.git\n",
        "%cd ATP_kurssi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-t05LqClCDs",
        "outputId": "a09b1ed4-c08d-487e-cd90-812c2bb4a22a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! cat en_one_per_line.txt | head -5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Travel\n",
            "Tips,tricks\n",
            "and\n",
            "Beautiful\n",
            "Destinations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K2to1Ru6kLZ",
        "outputId": "2bd05a7a-d6f9-430e-ebf7-6d6915134ea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#! cat en_one_per_line.txt | egrep \"is\" | head -4 # any line with the string\n",
        "#! cat en_one_per_line.txt | egrep \"^is\" | head -4 # lines starting with is \n",
        "! cat en_one_per_line.txt | egrep \"is$\" |  egrep -v \"^is$\"| head -4 # lines ending with is"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debris\n",
            "This\n",
            "This\n",
            "this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCDaBsJ37TOH"
      },
      "source": [
        "#! cat en_one_per_line.txt | egrep \"^.is\" | head -10 # line start, any character, is \n",
        "#! cat en_one_per_line.txt | egrep \"^(F|f).ing$\" # start, f or F, any character 0 or more times, ing, line end = string starting with f or F and ending with ing"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVEzX54C9M5v"
      },
      "source": [
        "! cat en_one_per_line.txt | egrep \"ing$\" # any line ending with ing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et5sAq4I-Fn8"
      },
      "source": [
        "! cat en_one_per_line.txt | egrep \"^[[:upper:]]\" # any line starting with a capital letter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk27BCK19RTR"
      },
      "source": [
        "! ! cat en_one_per_line.txt | egrep \"[a-zA-Z],[a-zA-Z]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPntXlui9mjc"
      },
      "source": [
        "! cat en_one_per_line.txt | egrep \"[a-zA-Z][[:punct:]][a-zA-Z]\" | sort | uniq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWiwdFQZ9-xV"
      },
      "source": [
        "! cat en_one_per_line.txt | egrep \"^[[:punct:]][a-zA-Z]\" | sort | uniq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsRK3bqd_P8s"
      },
      "source": [
        "! cat en_one_per_line.txt | egrep \"^[[:punct:]]*[a-zA-Z]+[[:punct:]][a-zA-Z]\" | sort | uniq  # What about combining the the previous ones? Note that you need to add + to the first letters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxAcQW2a3-gZ"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Let's have a closer look at the words we find from the en_one_per_line.txt file\n",
        "- How many (different) words start with c? What about if you take both upper and lower case? What are the most frequent ones?\n",
        "- What about words that end in \"ing\"? How many? What are the most frequent?Remember to normalize!\n",
        "----------------\n",
        "- How many (different) words start with a capital letter? What are they?\n",
        "- How many (different) words have upper case letters only?\n",
        "- How many (different) words include both upper and lower case letters?\n",
        "- How would you match words that start with lower case letter but have upper case letter(s) later on? Do you find any?\n",
        "---------------------\n",
        "Let's take a closer look at strings that have both  punctuation / numbers and letters \n",
        "- How many lines have both letters and punctuation?\n",
        "- What about letters and numbers?\n",
        "- At least lines that have punctuation between letters are tokenisation errors. How many do you find? How do they look like?\n",
        "\n",
        "Note: you can quite easily make a dummy sentence-splitter with regexes! What would be the punctuation marks you want to use for splitting sentences? what problems might there be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYAAkMdDoaIo"
      },
      "source": [
        "! cat en_one_per_line.txt | egrep \"^c\" | wc -l\n",
        "! cat en_one_per_line.txt | egrep \"^C\" | wc -l \n",
        "! cat en_one_per_line.txt | egrep \"^C|c\" | wc -l "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko5ZvghAvTJv"
      },
      "source": [
        "! cat en_one_per_line.txt | tr '[:lower:]' '[:upper:]' | egrep \"ING$\" | sort | uniq -c | sort -rn | head -10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeFXj4a1pFqR"
      },
      "source": [
        "#! cat en_one_per_line.txt | egrep \"^[[:upper:]]\" | wc -l\n",
        "#! cat en_one_per_line.txt | egrep \"^[[:upper:]]\" | sort | uniq -c | sort -nr | head -10\n",
        "#  cat en_one_per_line.txt | egrep \"^[[:upper:]]\" | sort | uniq | wc -l\n",
        "#! cat en_one_per_line.txt | egrep \"^[[:upper:]]+$\" | sort | uniq -c | sort -rn\n",
        "#! cat en_one_per_line.txt | egrep \"^([[:upper:]]+[[:lower:]]+)|^([[:lower:]]+[[:upper:]]+)\" | head -5\n",
        "! cat en_one_per_line.txt | egrep \"^[[:lower:]]+[[:upper:]]+\" | head -5"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB2vNEQcQdJe"
      },
      "source": [
        "### Exercise with tweets\n",
        "* *cut* command is useful for handling data in colums\n",
        "* it specifies the column to be used (by default columns are separated by a tab)\n",
        "* so ! cat tweets_en_nort.csv | cut -f 5 prints the 5th column\n",
        "\n",
        "Let's use tweets_en_nort.csv\n",
        "* What are the most frequent user names, in column 5?\n",
        "* Column 3 has the actual tweet texts. Focus on these. Examine the most frequent words. After these, you'll see that the texts have a lot of hashtags\n",
        "* What are the most frequent hashtags in the texts? What are about mentions (starting with @)\n",
        "* The tweet time stamps are in column 14. When are the tweets published?\n",
        "\n",
        "Advanced: the tweets have a lot of different Je suis X variations. How could you get the most frequent Xs? \n",
        "\n",
        "Note: if you want to have Xs futher than the next word, you need some tricks. I simply made a regex to split \"sentences\" to lines and decided that anything after \"je suis\" in the same \"sentence\" is the X.\n",
        "\n",
        "Note 2: tr is nice, but sometimes the similar functionality works better with a small perl script: perl -pe 's/ORIGINAL/REPLACED/g' \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNpJ285YxYUo"
      },
      "source": [
        "! cat tweets_en_nort.csv | cut -f 1,2,3,4 | head -5"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}