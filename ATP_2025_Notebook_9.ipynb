{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/ATP_kurssi/blob/master/ATP_2025_Notebook_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topics of this notebook:\n",
        "*  Thu 27 Nov 2025\n",
        "   * Recap of last week\n",
        "   * Lots of exercises to strengthen your basic skills\n",
        "*  Mon 01 Dec 2025\n",
        "   * Perl\n",
        "   * Exercises regarding the use of Perl\n",
        "\n",
        "**Please use the server to do these exercises. If you are stil unsure how scripts work, you can also recap the hands-on exercises listed in Notebook 8.**"
      ],
      "metadata": {
        "id": "TpumeODz_oAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recap of last week\n",
        "\n",
        "Commands:\n",
        "\n",
        "* `cd`\n",
        "* `pwd`\n",
        "* `mkdir`\n",
        "* `nano`\n",
        "* `emacs`\n",
        "* `less`\n",
        "* `cp`\n",
        "* `mv`\n",
        "* `rm`\n",
        "* `rmdir`\n",
        "* `echo`\n",
        "\n",
        "Scripting:\n",
        "\n",
        "* hashbang\n",
        "* permissions\n",
        "* executing\n",
        "* feeding data through stdin (pipe)\n",
        "* feeding data with arguments\n"
      ],
      "metadata": {
        "id": "izxz-bnPQvaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-on 9-1\n",
        "\n",
        "### 9-1.1\n",
        "The Github repo https://github.com/MarkHershey/CompleteTrumpTweetsArchive has all the tweets published by Donald Trump when he was at office. **Clone** the repository to your home folder on the server.\n",
        "\n",
        "### 9-1.2\n",
        "Count the most frequent hashtags (#) and / or handles (@) of the dataset covering Tweets when Trump was in office. Make sure to ignore possible punctuations to avoid losing data, e.g.:\n",
        "```\n",
        "@realDonaldTrump:\n",
        "@realDonaldTrump\n",
        "```\n",
        "### 9-1.3\n",
        "Make a script that takes a handle as an argument and prints out its distribution over time month by month. Run the script on a couple of interesting handles / hashtags. Do you see any trends?\n",
        "\n",
        "**Extra:** sort the output so that you have the tweets ordered from older to newer, followed by the number of tweets for that time stamp, like this:\n",
        "\n",
        "```\n",
        "YEAR-MONTH1 NUM-OF-TWEETS\n",
        "YEAR-MONTH2 NUM-OF-TWEETS\n",
        "```\n",
        "If you get a permission denied error, you have forgotten to add execution rights to your script. This can be done with `chmod a+rwx file.txt`\n",
        "\n",
        "### 9-1.4\n",
        "Make another script that takes a handle as an argument and prints out a cleaned and normalized frequency list of the words that occur in the tweets with the handle.\n",
        "\n",
        "You can try out different ways of cleaning the data. Does it make sense to include tokens with numbers and / or punctuation at all? Or is it better to just, e.g., delete tokens and numbers and otherwise keep the strings there?"
      ],
      "metadata": {
        "id": "2YaAm2zJ0jGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-on 9-2\n",
        "\n",
        "Finnish parliamentary speeches have been published in parlamenttisampo.fi but it is difficult to get large amounts of data from there. Luckily the full datasets are available as yearly CSV files here:\n",
        "https://a3s.fi/parliamentsampo/speeches/csv/index.html\n",
        "\n",
        "Unlucky for us, the format of the file is not optimal for our tools, but let's see what we can get out of it anyway.\n",
        "\n",
        "### 9-2.1\n",
        "\n",
        "Get the speech file for year 2020. Browse the file to see what it contains. Notice how it is comma separated and how the actual speech (\"content\") is separated by double quotes. More advanced tools could handle that, but out cut tool cannot.  \n",
        "\n",
        "(N.B. A good way to deal with this would be to use e.g. Python and the Pandas library, but that is advanced stuff. We will make do with our simple tools.)\n",
        "\n",
        "Make a pipe that only uses the first line of text (containing the headers) and prints a list of headers, one per line.\n",
        "\n",
        "### 9-2.2\n",
        "\n",
        "Find out who gave the most speeches in 2020 (use \"name_in_source\").\n",
        "\n",
        "### 9-2.3\n",
        "\n",
        "Find out which months were the most active (most speeches given) and which months were the least active (least speeches given) for debate.\n",
        "\n",
        "Which months are missing? Why do you think this is?\n",
        "\n",
        "### 9-2.4\n",
        "\n",
        "Try to find out the most dicussed topic.\n",
        "\n",
        "### 9-2.5\n",
        "\n",
        "Try to find out the party that spoke the most often."
      ],
      "metadata": {
        "id": "_5nGP97Su2Re"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "F5vCKvKDoy7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PERL command in Bash\n",
        "\n",
        "Perl is a programming language, and ```perl``` is a command to use Perl language for certain things within Bash. Extra info here if you are interested: https://www.computerhope.com/unix/uperl.htm\n",
        "\n",
        "A perl script can be useful for modifying strings of text. The example below would replace all instances of ORIGINAL with REPLACEMENT; this will be the only way we will be using Perl during this course despite Perl's versatility in scipting.\n",
        "\n",
        "```\n",
        "cat inputfile.txt | perl -pe 's/ORIGINAL/REPLACEMENT/g'\n",
        "```\n",
        "\n",
        "Perl supports regex!\n",
        "\n",
        "Perl script also supports back reference, so you can refer to regex capture groups (denoted by braces ```()```) in `ORIGINAL` with a `$` in `REPLACEMENT`. For example, below any punctuation is replaced by a newline and that punctuation:\n",
        "\n",
        "```\n",
        " perl -pe 's/([[:punct:]])/\\n$1/g'\n",
        "```\n"
      ],
      "metadata": {
        "id": "jsJ7sN-zDRPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXTRA: Understanding the perl command structure (not asked in the exam)\n",
        "\n",
        "The ```-pe``` flags:\n",
        "\n",
        "* ```-p``` wraps the script in a loop that reads input line by line, applies the script, and prints the result.\n",
        "\n",
        "* ```-e``` lets you provide the Perl code directly on the command line.\n",
        "\n",
        "So ```-pe``` runs your substitution regex on every line of input and prints the modified line.\n",
        "\n",
        "The ```s``` at the start just means \"substitute\".\n",
        "\n",
        "The ```g``` at the end means \"global\". Without ```g```, Perl would replace only the first match of the pattern in a line. With ```g```, Perl replaces all matches of the pattern in the line."
      ],
      "metadata": {
        "id": "3ngWJlavTj6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reminder about multi-line scripts\n",
        "\n",
        "Note that in a multi-line script file, you can have various commands each on their own line and independent of each other. The lines will be executed one by one (with the exception of pipes, where the piped commands are all executed in one step).\n",
        "\n",
        "For instance, if a script has the two commands below, it will first print \"kukkuu\" to a file called delme.txt, and then, independent from the first command, print the file and egrep lines that include the string \"kuu\".\n",
        "\n",
        "```\n",
        "echo \"kukkuu\" > delme.txt\n",
        "cat delme.txt | egrep \"kuu\"\n",
        "```\n",
        "This is different from dividing one command to multiple lines, e.g.\n",
        "\n",
        "```\n",
        "cat \"kukkuu.txt\"\n",
        "  | perl -pe 's/kuu/muu/g'\n",
        "  | egrep \"muu\"\n",
        "```\n",
        "where the indentations show that the pipe continues on those lines."
      ],
      "metadata": {
        "id": "I9CQKciTHTyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hands-on 9-3\n",
        "\n",
        "### 9-3.1\n",
        "\n",
        "Formulate a one-line pipeline that\n",
        "\n",
        "a) creates a file that contains this string of text on one line:\n",
        "```\n",
        "These are the rules:BREAKJava is trashBREAKPython is coolBREAKAnd so is Bash\n",
        "```\n",
        "b) uses the `perl` substitution command to change all `BREAK` words into newlines `\\n`\n",
        "\n",
        "c) egreps all lines that have the word \"is\"\n",
        "\n",
        "### 9-3.2\n",
        "\n",
        "a) Make a script file called ```temp_rules.sh``` that contains the previous pipeline but divided on multiple lines for readability (remember to indent!).\n",
        "\n",
        "b) Then add one command to the beginning of the script that prints the text string \"RULES:\", then add another command to the end of the script that prints a newline and (`--Anna`).\n",
        "\n",
        "c) Modify the last line so that you can give any name as an argument (replace \"Anna\" with something).\n",
        "\n",
        "### 9-3.3\n",
        "\n",
        "Modify the Perl script so that it finds all instances of \"is \" that are followed by a lowercase character and substitutes them with \"is super \", like this:\n",
        "```\n",
        "Python is cool >>>> Python is super cool\n",
        "And so is Bash >>>> And so is Bash\n",
        "```\n",
        "Use regex capture groups and back reference!!\n"
      ],
      "metadata": {
        "id": "pUoxGrTHNlZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hands-on 9-4\n",
        "\n",
        "Get a copy of a recipe dataset from here:\n",
        "\n",
        "`/home/ankrris/data/recipes_modified.csv`\n",
        "\n",
        "Inspect the file. Then do the following:\n",
        "\n",
        "a) Find out how many recipes do not use tomatoes in the \"ingredients\" column.\n",
        "\n",
        "b) Replace every \"potato\" with \"tomato\". Now how many recipes do not use any tomatoes in the \"ingredients\" column?\n",
        "\n",
        "d) Replace every \"tomato\" and \"potato\" with \"pomato\" in a single Perl substitution.\n",
        "\n",
        "e) Replace every word that begins with an uppercase letter with that same word plus \"-ho\". E.g. \"Place\" >>>>> \"Place-ho\". Provide the file to the script as an argument."
      ],
      "metadata": {
        "id": "HFsZQcvONvVv"
      }
    }
  ]
}